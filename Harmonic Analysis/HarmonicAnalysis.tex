\documentclass[palatino]{epflnotes}

\title{Harmonic Analysis}
\author{Guillermo Julián Moreno}
\date{16/17 - Spring semester}

% Additional packages

\precompileTikz
% --------------------

\begin{document}
\frontmatter
\pagestyle{plain}
\maketitle

\tableofcontents
\mainmatter
% Content

\chapter{Fourier analysis}

\section{Basic structures in Banach and Hilbert spaces}

Fourier analysis is the study of how Fourier series and Fourier transforms work, and these are esentially a ``change of basis'' in the space of functions. In order to study them correctly, we will first review some facts of the structure of functions in Banach and Hilbert spaces. Just remember that the $L_p$ spaces defined by \[ L_p(Ω) = \set{\appl{f}{Ω}{ℝ} \st \norm{f}_{L^p} ≝ \left(\int_{Ω} \abs{f}^{p} \dif μ\right)^{\sfrac{1}{p}} < ∞ } \] for $1≤ p ≤ ∞$, $Ω ⊂ ℝ^d$ and μ a corresponding measure for Ω, are Banach spaces. In the particlar case of $p = 2$ we have a Hilbert space with the scalar product defined as \[ \pesc{f,g} = \int_Ω f \conj{g} \dif μ \]

In these spaces we can define an operation, the convolution, which will become useful in the analysis of Fourier series.

\subsection{Convolution and approximate identities}

\begin{defn}[Convolution] \label{def:Convolution} Given two functions $f ∈ L^p(Ω)$ and $g ∈ L^q(Ω)$, the convolution of both is defined as \[ (f \ast g) (x) ≝ \int_Ω f(x-y) g(y) \dif y\]
\end{defn}

The convolution is an operation that ``plays nicely''. It has the follwing result giving a bound on the norm of the convolution.

\begin{prop} \label{prop:YoungInequality} Let $1 ≤ p,q,r ≤ ∞$, and let $f ∈ L^p(Ω)$, $g ∈ L^q(Ω)$. Then, \[ \norm{f*g}_r≤ \norm{f}_p \norm{g}_q \] and so $f \ast g ∈ L^r(Ω)$ when $1 + \frac{1}{r} = \frac{1}{p} + \frac{1}{q}$.

In particular, if $g ∈ L^1$ and $f ∈ L^p$, then $f * g ∈ L^p$.
\end{prop}

It also goes well with continuous functions.

\begin{prop} \label{prop:ConvolutionContinuous} Let $f ∈ C^0(Ω)$ and $g ∈ L^1(Ω)$. Then $f * g ∈ C^0(Ω)$.
\end{prop}

\begin{proof} Let $y ∈ Ω$ such that $\abs{x - y} < δ$. We can try and bound so that \begin{align*}
\abs{(f*g)(x) - (f*g)(y)}
	&= \abs{\int_Ω f(x - t) g(t) \dif t - \int_Ω f(y - t) g(t) \dif t} = \\
	&= \abs{\int_Ω f(x - t) - f(y - t) g(t) \dif t } ≤ \\
	&≤ \int_Ω \abs{f(x - t) - f(y - t)} \abs{g(t)} \dif t ≤ \\
	&≤ ε \int_Ω \abs{g(t)} \dif t ≤ ε \norm{g(t)}
\end{align*} and we have it.
\end{proof}

The convolution does not have an identity in the space of functions, as there is no function $φ$ such that $φ * f = f$. However, we can construct approximations:

\begin{defn}[Approximate\IS identity] \label{def:ApproximateIdentity} A family of functions $\set{φ_N}_{N ≥ 0} ⊂ L^∞(Ω)$ is called a family of approximate identities if and only if:
\begin{enumerate}
	\item $\int_Ω φ_N = 1$.
	\item $\sup_{N ≥ 0} \norm{φ_N}_{L^1} < ∞$.
	\item Their support goes to zero. That is, for any $δ > 0$ the following holds: \[ \lim_{N \to ∞} \int_{\abs{x} > δ} \abs{φ_N} = 0\]
\end{enumerate}
\end{defn}

The main property of these functions is that they are indeed approximations of the identity element for the convolution:

\begin{prop} \label{prop:ApproximateIdentity} Let $\set{φ_N}_{N ≥ 0}$ be a family of approximate identities, and let $f ∈ L^p(Ω)$ for $1 ≤ p < ∞$. Then, \[ \lim_{N \to ∞} \norm{φ_N * f - f}_p = 0 \]
\end{prop}

\begin{proof}

\proofpart{$p = 1$}

We prove it first for $p = 1$. There, operating we have
\begin{align*}
\norm{φ_N * f - f}_1
	&= \int_Ω \abs{(φ_N * f)(x) - f(x)} \dif x = \\
	&= \int_Ω \abs{\int_Ω φ_N(y) f(x - y) \dif y - f(x) \underbracket{\norm{φ_N}_1}_{=1}} \dif x ≤ \\
	&≤ \int_Ω \int_Ω \abs{φ_N(y)} \abs{f(x-y) - f(x)} \dif y \dif x = \\
	&= \int_Ω \abs{φ_N(y)} \int_Ω \abs{f(x-y) - f(x)} \dif x \dif y = \\
	&= \int_Ω \abs{φ_N(y)} \norm[0]{T_yf - f}_1 \dif y
\end{align*} where $T_y f(x) ≝ f(x - y)$ is the translation operator, and where we have used Fubini's theorem to interchange the order of the integrals.

Now we will use the ``support goes to zero'' property of the approximate identity to separate the integral in two parts: one where the approximate identity goes to zero ($\abs{y} > δ$ for some $δ > 0$) and other where we will use properties of the translation operator.

So, for the first part we have \begin{align*}
\int_{\abs{y} > δ} \abs{φ_N(y)} \norm[0]{T_yf - T_0 f}_1 \dif y
	&≤ \int_{\abs{y} > δ} \abs{φ_N(y)} \left(\norm[0]{T_y f}_1 + \norm[0]{T_0 f}_1\right) \dif y \\
	&≤ 2\norm{f}_1 \int_{\abs{y} > δ} \abs{φ_N(y)} \dif y \convs[][N][∞] 0
\end{align*}

The second is a little bit more complex. As $C^∞(Ω) \densein L^p(Ω)$, choose a $g ∈ C^∞(Ω)$ such that $\norm{f - g}_1 < ε$ for any $ε < 0$. Now, adding and substracting $T_yg$ and $g$ we have that \begin{align*}
\norm[0]{T_y f - f}_1 &= \norm[0]{T_y f - T_y g + T_yg - g + g - f} ≤ \\
	&≤ \norm[0]{T_y f - T_y g}_1 + \norm{T_y g - g}_1 + \norm{g - f} ≤ \\
	&≤ (\norm[0]{T_y} + 1)\norm{f - g} + \norm[0]{T_y g - g}_1 \convs[][y][0] 0
\end{align*} as $\norm[0]{T_y g - g} = \int_Ω g(x - y) - g(x) \dif x$ goes to zero because we chose $g ∈ C^∞$. With that, we complete the proof for $p = 1$.

\proofpart{$1 < p < ∞$}

In \fref{prop:YoungInequality} we proved that if $φ_N ∈ L^1$ and $f ∈ L^p$, then $φ_N * f ∈ L^p$. Then, it makes sense to compute the $p$-norm of $φ_N * f - f$ as that is in $L^p$, and we can bound it as $\norm{φ_N * f - f}_p ≤ \norm{φ_N * f - f}_1$.

\end{proof}

If we ask for a little bit more of regularity, we have even uniform convergence.

\begin{prop} \label{prop:ApproximateIdentityUnif} Let $f ∈ C_0(Ω)$ and $\set{φ_N}_{N > 0}$ a family of approximate identities. Then, $φ_N * f \to f$ uniformly.
\end{prop}

\begin{proof} We will proceed to prove convergence in $L^∞(Ω)$, and that together with \fref{prop:ConvolutionContinuous} (the convolution of $L^1$ functions with a continuous function is continuous) will prove uniform convergence.

The proof is not difficult as it is just repeating the previous arguments, interchanging integrals and then using ``support goes to zero'' to bound for $\abs{y} > δ$ and continuity of $f$ when $\abs{y} < δ$.
\end{proof}

\section{Fourier series}

The first tool in harmonic analysis will be the Fourier series, which allows representation of a function as a trigonometric polynomial.

\begin{defn}[Fourier\IS series] Given $f ∈ C^0(\crc[1])$, we can define its Fourier series with coefficients \[ \hat{f}(n) = \int_0^1 e^{-2π\imath n x} f(x) \dif x \qquad n ∈ ℤ \] as \( \sum_{n ∈ ℤ} \hat{f}(n) e^{2π\imath n x} \label{eq:FourierSeries} \)
\end{defn}


In our case, we will consider $\crc[1]$ as the space of periodic functions, so equivalently $\crc[1] \cong \quot{ℝ}{ℤ}$. One interesting property of the Fourier series is its relation to the convolution.


With this, one can see the relationship between the convolution and the Fourier transform.

\begin{prop} Consider $f, g ∈ C^0(\crc[1])$. Then, the Fourier series of the convolution is the same that the product of the Fourier series: \[ \widehat{f\ast g} (n) = \hat{f}(n) · \hat{g}(n)\]
\end{prop}

\begin{proof} % TODO
\end{proof}

\subsection{Convergence for continuous functions}
\label{sec:Fourier:ConvergenceContinuous}

\begin{figure}[hbtp]
\centering
\inputtikz{DirichletKernel}
\caption{Dirichlet kernel for different values of $N$.}
\label{fig:DirichletKernel}
\end{figure}

We will start off trying to prove convergence in ``easy'' situations, that is, those with continuous functions. We will have to turn to the \concept[Kernel\IS Dirichlet]{Dirichlet kernel}, defined as \( \label{eq:DirichletKernel} D_N(x) ≝ \sum_{\abs{n} ≤ N} e^{2π\imath n x} = \frac{\sin \left(2πt (N + \sfrac{1}{2})\right)}{\sin πt} \), mainly because it has the interesting property that $S_Nf = D_N \ast f$, which allows a better treatment of the Fourier series. With a little bit of calculations (see \cite[Exercise 2.4]{ApuntesAnalisisFunc}) one can also show that \( \label{eq:DirichletKernelNormL1} \norm{D_N}_{L^1(\crc[1])} = C \log N + \mathcal{O}(1) \) so that the Dirichlet kernel is unbounded.

This allows us to prove the following proposition of non-convergence of the Fourier series for continuous functions.

\begin{prop} \label{prop:ConvergenceFourierCont} There exists at least a function $f ∈ C^0(\crc[1])$ for which the Fourier series does not converge pointwise. That is, such that \[ \lim_{N \to ∞} \abs{S_Nf(0) - f(0)} = ∞ \]
\end{prop}

\begin{proof}
The proof here is a summary of \cite[Exercise 2.4]{ApuntesAnalisisFunc}. Define the operator $λ_{D_N}(f) = S_Nf(0)$ on the space of continuous functions $X =(C^0(\crc[1]), \norm{·}_∞)$, which is Banach. Each of the operators are bounded with $\norm{λ_{D_N}}_{\linapp[X][ℝ]} = \norm{D_N}_{L^1(\crc[1])}$. However, this family of operators is not uniformly bounded so the \nref{thm:BanachSteinhaus} says that there exists a set $B$ dense in $X$ such that \[ \sup_{N ≥ 1} \norm{λ_{D_N} (f)}_{ℝ} = \sup_{N ≥ 1} \norm{S_N f(0)}_{ℝ} = ∞ \quad ∀f ∈ B\] and thus $\norm{S_Nf(0)}_{ℝ}$ is divergent for those $f ∈ B$.
\end{proof}

So, in general, the Fourier series does not necessarily converge pointwise for $C^0$ functions. We will be able, however, to prove pointwise convergence asking just for a little bit of regularity.

\subsubsection{Pointwise convergence for Hölder functions}

Luckily for us, we can have pointwise convergence just by asking a little bit of regularity to the function being transformed. This will be Hölder continuity:

\begin{defn}[Hölder\IS continuous] A function $\appl{f}{X}{Y}$ between two metric spaces is Hölder continuous if there exists two constants $C > 0$, $α ≥ 0$ such that for any $x, y ∈ X$, the following holds: \[ \norm{f(x) - f(y)} ≤ C \norm{x-  y}^α\]
\end{defn}

Obviously, if $α = 0$ we have boundedness, for $α > 0$ continuity and for $α = 1$

\begin{prop} \label{prop:FourierConvHolder} If $f ∈ C^0(\crc[1])$ is Hölder continuous, then the Fourier series of a function is equal to the same function.
\end{prop}

\begin{proof} We want to prove that, $∀x ∈ \crc$, the following limit is null: \[ \lim_{N \to ∞} S_Nf(x) -f(x) = 0\]

In order to do that, we will put the $f(x)$ inside of the integral and separate it in two intervals: one in which we will use the regularity of $f$ to compensate for the growth of the Dirichlet kernel and another one where we will use the oscillations of the kernel to bound the integral. Making use of the symmetry of $D_N$ we have that \begin{align*}
S_Nf(x) - f(x) &= \int_0^1 \left(f(x-y) - f(x)\right) D_N(y) \dif y = \int_{-\sfrac{1}{2}}^{\sfrac{1}{2}} \left(f(x-y) - f(x)\right) D_N(y) \dif y = \\
&= \underbracket{\int_{\abs{y} < δ} \left(f(x-y) - f(x)\right) D_N(y) \dif y}_{A} +
	\underbracket{\int_{\sfrac{1}{2} > \abs{y} > δ} \left(f(x-y) - f(x)\right) D_N(y) \dif y}_{B}
\end{align*}

For the estimate of $A$ we use the Hölder continuity:
\begin{align*}
\abs{A}
	&≤ \int_{\abs{y} < δ} \abs{\left(f(x-y) - f(x)\right) D_N(y)} \dif y  \\
	&≤ \int_{\abs{y} < δ} C \norm{x-y - x}^α \abs{D_N(y)} \dif y  \\
	&≤ Cδ^α \int_{\abs{y} < δ} \abs{D_N(y)} \dif y \\
	&\eqexpl[≤]{\eqref{eq:DirichletKernelNormL1}} Cδ^α \log N
\end{align*}

% TODO: Fix and end this proof
\end{proof}

\subsubsection{Césaro sums - Pointwise convergence for $C^0$ functions}

In the previous sections we have shown that, while the Fourier series is convergent pointwise for Hölder functions, it can even be divergent for general $C^0$ functions. However, we can recover pointwise values using averages over the coefficients, by means of the Césaro sum.

\begin{defn}[Césaro\IS means] Given $f ∈ C^0(\crc)$, we define the Césaro mean as \[ σ_N f(x) ≝ \frac{1}{N} \sum_{n = 0}^{N-1} S_n f(x) = \frac{1}{N} \int_0^1 \underbracket{\left(\sum_{n = - (N-1)}^{N-1} (N - \abs{n}) e^{2π\imath nx}\right)}_{K_N(x)} f(y) \dif y \]
\end{defn}

That expression $K_N$ is what we will call the \concept[Kernel\IS Féjer]{Féjer kernel}, and has the following expression: \( \label{eq:FejerKernel} K_N(x) = \frac{1}{N} \left(\frac{\sin πNx}{\sin πx}\right)^2 \)

\begin{figure}[hbtp]
\centering
\inputtikz{FejerKernel}
\caption{Fejer kernel for several values of $N$.}
\label{fig:FejerKernel}
\end{figure}

As opposed to the Dirichlet kernel, the Féjer kernel is positive and bounded in norm, forming what we call an \nlref{def:ApproximateIdentity}\footnote{Verification left to the untrusting reader.}. As it can be seen in \fref{fig:FejerKernel}, its supports tends to be smaller and smaller while maintaining area, which is the main property of these approximations.


With this proof we can show that the Césaro means actually converge to the value of the function.

\begin{corol} Let $f ∈ C^0(\crc)$. Then, the Césaro means (that is, the averages of its Fourier coefficients) converge pointwise to the function: \[ \lim_{N \to ∞} σ_N f(x) = f(x)\]
\end{corol}

\begin{proof} As we saw previously, the Césaro means can be expressed as $σ_N f = K_N * f$, and as $K_N$ is an \nlref{def:ApproximateIdentity} we can apply \fref{prop:ApproximateIdentityUnif} to have the result.
\end{proof}

\subsection{General convergence results}

In the more general framework of $L^p$ functions we can still prove interesting results about the Fourier series. The most important is the fact that the functions $\set{e^{2π\imath nx}}$ are dense in $L^p(\crc)$ for $1 ≤ p < ∞$. In the specific case of $p = 2$, which is a Hilbert space, that will imply that they are a basis of the space, thanks to the fact that the functions are orthonormal\footnote{Recall the inner product is defined as $\pesc{f,g} = \int_0^1 f \conj{g}$.}.

\begin{prop} \label{prop:TrigoPolyDense} The trigonometric family of functions $\set{e^{2π \imath nx}}_{n ∈ ℤ}$ is dense in $L^p(\crc)$ for $1 ≤ p < ∞$.
\end{prop}

\begin{proof} Using the Féjer kernel, as $K_N * f$ is a trigonometric polynomial we can just apply \fref{prop:ApproximateIdentity}.
\end{proof}

This allows us to prove in a very straightforward way the following theorem:

\begin{theorem}[Riesz–Fischer\IS theorem]\label{thm:RieszFischer} Let $f ∈ L^2(\crc[1])$ and define its partial Fourier series as \( \label{eq:PartialFourier} S_Nf(x) = \sum_{ \abs{n} ≤ N} \hat{f}(n) e^{2π\imath nx} \)

Then, $S_Nf$ converges to $f$ in the $L^2$ norm: \[ \norm{S_Nf - f}_{L^2(\crc[1])} = 0 \]
\end{theorem}

\begin{proof} Just apply \fref{prop:TrigoPolyDense}.
\end{proof}

The question is what happens in the general case $1 ≤ p ≤ ∞$. We have the following proposition which answer it partially:

\begin{prop} \label{prop:FourierSeriesConvLp} Let $1 ≤ p ≤ ∞$. Then we have convergence of the Fourier series in $L^p$ norm if and only if $\norm{S_N}_{\linapp[L^p(\crc)][L^p(\crc)]}$ is uniformly bounded. That is,
\[ \lim_{N \to ∞} \norm{S_N f - f}_{L^p(\crc)} = 0 \iff \sup_{N > 0} \norm{S_N}_{\linapp[L^p(\crc)][L^p(\crc)]} < ∞ \] for all $f ∈ L^p(\crc)$ and where, as a reminder, we define the operator norm as \[ \norm{S_N}_{\linapp[L^p(\crc)][L^p(\crc)]} ≝ \sup_{\substack{f ∈ L^p(\crc) \\ \norm{f} ≤ 1}} \norm{S_N f}_{L^p(\crc)}\]
\end{prop}

\begin{proof} We will separate the proofs in the if and only if parts. For convenience, we will drop the subscripts for the norms where its meaning is clear.

\proofpart{If: $\sup_{N > 0} \norm{S_N} <∞ \implies \lim_{N \to ∞} \norm{S_N f - f} = 0$}

Say $M ≝ \sup_{N > 0} \norm{S_N}$. As $C^∞(\crc) \densein L^p(Ω)$, we can choose a $g ∈ C^∞(\crc[1])$ such that $\norm{f - g} < ε$. Adding and substracting it in the norm, we can bound it:
\begin{align*}
\norm{S_Nf - f}
	&= \norm{S_Nf - f + g - g + S_N g - S_N g} = \\
	&= \norm{S_N(f - g) + (g - f) + (S_N g - g)} ≤ \\
	&≤ \norm{S_N(f -g)} + \norm{g -f} + \norm{S_N g - g} ≤ \\
	&≤ M ε + ε + ε
\end{align*} where we use, in order, the fact that $S_N$ is uniformly bounded, the approximation $g \to f$ and the fact that $S_N g \to g$ for smooth functions (\fref{prop:FourierConvHolder}, smooth functions are Hölder continuous).

\proofpart{Only if: $\lim_{N \to ∞} \norm{S_N f - f} = 0 \implies \sup_{N > 0} \norm{S_N} <∞$}

We will do this proof by contradiction: assume that $\lim_{N \to ∞} \norm{S_N f - f} = 0$ but $S_N$ are not uniformly bounded. By the \nref{thm:BanachSteinhaus}, we have that there exists a $G_δ$ set $B \densein L^p(\crc[1])$ such that $\sup_{N > 0} \norm{S_Nf} = ∞$ for all $f ∈ B$, and as $\norm{S_Nf -f } ≥ \norm{S_N f} - \norm{f}$ we have the contradiction.

\end{proof}

This gives us the following result for $p = 1$ and $p = ∞$:

\begin{prop} For $p = 1, ∞$, there exists at least a $f ∈ \crc$ such that \[ \lim_{N \to ∞} \norm{S_N f - f}_{L^p(\crc)} ≠ 0 \]
\end{prop}

\begin{proof} Simply use \fref{prop:FourierSeriesConvLp} knowing that $S_N f = D_N * f$ and that $\norm{D_N}_p \convs[][N][∞] ∞$ for $p = 1, ∞$.
\end{proof}


So, we proved non-convergence for $p = 1, ∞$ (in fact we even proved non-pointwise convergence in the case of continuous functions in \fref{prop:ConvergenceFourierCont}) and convergence for $p = 2$ (\fref{thm:RieszFischer}). For the other cases we will have convergence although we will see it later with a little bit more of work.

\subsection{Regularity and decay of Fourier coefficients}

One of the most useful aspects of the Fourier transform is the translation of derivation in the function space to multiplication in the Fourier coefficients. Indeed, one can compute and see that \[ \widehat{f'}(n) = \int_0^1 f'(x) e^{-2π\imath n x} \dif x = \eval[1]{f(x) e^{2π\imath nx}}_{x = 0}^1 + \int_0^1 2π\imath n f(x) e^{-2π\imath nx} \dif x = 2π\imath n \hat{f} (n) \]

Furthermore, if we have a previous bound on $\abs{\widehat{f'}(n)} < C$, then we can bound $\hat{f}(n)$ which will decay as \[ \abs{\hat{f}(n)} ≤ \frac{C}{2πn} \]

We will also be able to do the converse: control in the decay of the Fourier coeffiencts gives us control in the smoothness of $f$.

\begin{theorem} Assume $\hat{f}(k) = 0$ for all $\abs{k} > n$. Then, for any $1 ≤ p ≤ ∞$ we have there exists a constant $C > 0$ such that \[ \norm{f'}_p ≤ Cn \norm{f}_p \]
\end{theorem}

% Lecture3.pdf is not copied because I don't really now why is it done.

\section{Fourier transform}

Now we can move to the Fourier transform on a general space $ℝ^n$. We will start defining it for a class of ``good functions'' and then start working our way up from there.

\subsection{Fourier transform on Schwartz spaces}

This class of very nice functions will be the Schwartz space:

\begin{defn}[Schwartz space][Space!Schwartz] The Schwartz space is defined as \[ \schwartz = \set{ f ∈ C^∞(ℝ^n) \st \sup_{x ∈ ℝ^n} \abs{(1 + \abs{x}^N) ∂_x^α f(x)} < ∞ } \] for any $N ∈ ℕ$ and any multiindex $α ∈ ℕ^n$.
\end{defn}

\begin{figure}[hbtp]
\inputtikz{SchwartzFunctions}
\caption{Some examples of Schwartz functions ($f_n$) and functions that are not in \schwartz ($g_n$) despite decaying to zero.}
\label{fig:SchwartzFunctions}
\end{figure}

This space contains ``rapidly decreasing functions'' (see \fref{fig:SchwartzFunctions} for some examples). It contains smooth functions with compact support (very useful for mollifiers), is an algebra (vector space invariant under multiplication of functions), invariant under differentiation and under multiplication with polynomials.

Now we can study what is the effect of the Fourier transform on this space. First, the definition of the transform:

\begin{defn}[Fourier\IS transform] For a given function $\appl{f}{ℝ^n}{ℝ}$, we define its Fourier transform as \( \fourier(f)(ξ) = \hat{f}(ξ) ≝ \int_{ℝ^n} f(x) · e^{-2πix · ξ} \dif x \qquad ξ ∈ ℝ^n \)
\end{defn}

It is easy to see that the integral converges absolutely if $f ∈ \schwartz$. Additionally, we have the following result:

\begin{prop} \label{prop:SchwartzFourierItself} The Fourier transform maps \schwartz onto itself. That is, $\fourier(\schwartz) ⊆ \schwartz$.
\end{prop}

\begin{proof} We need to prove that the Fourier transform of a Schwartz function is itself Schwartz. We can start by calculating the derivative of the function:
\begin{align*}
∂_ξ^α \hat{f}(ξ)
	&= \int_{ℝ^n} f(x) \left(∂_ξ^αe^{-2π\imath x·ξ}\right)\dif x = \\
	&= \int_{ℝ^n} (-2π\imath x)^α f(x) e^{-2π \imath x·ξ} \dif x = \\
	&= \fourier\left((-2π\imath x)^α f(x)\right)
\end{align*}

Now we recall that we can derivate by multiplying in Fourier space (that is, $\fourier(∂_x^βf) = (2π\imath ξ)^β \fourier(f)$), so that
\begin{align*}
(2π\imath ξ)^β · ∂_ξ^α \hat{f}(ξ)
	&= \fourier\left(∂_x^β \left[(-2π\imath x)^α f(x)\right]\right)
\end{align*} which is again absolutely convergent (Schwartz space is invariant under polynomial multiplication and derivation) and so we have our result.
\end{proof}

In fact we have a bijection, so that the Fourier transform operator is invertible.

\begin{theorem}[Fourier\IS inversion] Let $f ∈ \schwartz$ and $\hat{f}$ its Fourier transform. Then, the inversion formula holds: \( f(x) = \int_{ℝ^n} \hat{f}(ξ) e^{2π\imath x · ξ} \dif ξ \)
\end{theorem}

\begin{proof} We can start by expanding the definition of the Fourier transform:
\begin{align*}
f(x)
	&= \int_{ℝ^n} \hat{f}(ξ) e^{2π\imath x · ξ} \dif ξ =  \\
 	&= \int_{ℝ^n} \int_{ℝ^n} f(y) · e^{-2πiy · ξ} · e^{2π\imath x · ξ} \dif y \dif ξ
\end{align*}

We cannot, however, switch the order of integration because $\int e^{2π\imath (x-y) ξ} \dif ξ$ does not converge. We can introduce a damping factor and consider instead the function \[ \hat{f_ε}(ξ) ≝ \int_{ℝ^n} f(y) e^{-2π\imath y ξ - ε\abs{ξ}^2} \dif y = \hat{f}(ξ) e^{-ε\abs{ξ}^2} \] for $ε > 0$. It can be seen that $f_ε \convs[][ε][0] f$ and that $\abs{f_ε} ≤ f$ for all $ε > 0$, so that we can use the \nref{thm:DominatedConvergence} to switch the integral and the limit so that \[ \int_{ℝ^n} \hat{f}(ξ) e^{2π\imath x· ξ} \dif ξ = \lim_{ε \to 0} \int_{ℝ^n} \hat{f}_ε(ξ) e^{2π\imath x · ξ} \] and in the latter integral we will be able to interchange the order of integration as the integral converges absolutely.

% TODO: Complete this

\end{proof}

\subsection{Plancherel theorem and extension to $L^2(ℝ^n)$}

The Fourier inversion theorem allows us to prove the following theorem, which in turns allows the extension of the Fourier transform to $L^2$.

\begin{theorem}[Plancherel\IS theorem] \label{thm:Plancherel} The Fourier transform on \schwartz is an $L^2$ isometry. More precisely, for any $f,g ∈ \schwartz$ we have that \begin{align*}
\pesc{f, g} &= \pesc{\hat{f}, \hat{g}} \\
\int_{ℝ^n} f(x) \conj{g(x)} \dif x &= \int_{ℝ^n} \hat{f}(ξ) \conj{\hat{g} (ξ)} \dif ξ
\end{align*}
\end{theorem}

\begin{proof}
% TODO
\end{proof}

We need one extra step to prove the extension of the Fourier transform to $L^2$, and that is the density of $\schwartz$ in $L^p$ spaces.

\begin{prop} \label{prop:SchwartzLpDensity} The space $\schwartz$ is dense in $L^p(ℝ^n)$ for $1 ≤ p < ∞$\footnote{I don't know if this is provable for $p = 1, ∞$}.
\end{prop}

\begin{proof} First, see that if $f ∈ L^p$, for every $ε > 0$ we can find a $r > 0$ such that \[ \norm{f - \ind_{\bola_r(0)} f}_p < ε \]

In other words, we can approximate $f$ by itself supported only on a compact set. Now the problem is that $f_r ≝ \ind_{\bola_r(0)} f $ is not necessarily continuous. However, we can just pick a mollifier $φ_t$ such that $φ_t * f_r \to f_r$ and $φ_t * f_r ∈ \schwartz$. Combine these two approximations to see that we can indeed approximate any $f ∈ L^p$ by functions of \schwartz as good as we want.
\end{proof}

Now we can define the extended Fourier transform.

\begin{prop}[Fourier\IS transform on $L^2(ℝ^n)$] The Fourier transform is well defined on $L^2(ℝ^n)$.
\end{prop}

\begin{proof} Consider the integral \[ \hat{f}(ξ) = \int_{ℝ^n} f(x) e^{-2π\imath x · ξ} \dif x\] of the Fourier transform. We have two options: it can be well defined and converging, in which case there's nothing to prove, or it can not converge.

In the second case, as $\schwartz \densein L^2(ℝ^n)$, pick a Cauchy sequence $\set{f_n} ⊂ \schwartz$ such that $f_n \to f$. Now $\set{\hat{f_n}} ⊂ L^2(ℝ^n)$ is going to be Cauchy too by \nref{thm:Plancherel}, and as $L^2(ℝ^n)$ is complete it converges to a certain $\hat{f} ∈ L^2(ℝ^n)$. Thus, we need only to define \[ \hat{f} ≝ \lim_{n \to ∞} \hat{f_n} \]

\end{proof}

\subsection{Extension to general $L^p(ℝ^n)$ spaces}

Extension of the Fourier transform operator to general $L^p$ spaces. From the definition we can see that having $f ∈ L^1(ℝ^n)$ gives convergence and in fact something more.

\begin{prop} Given $f ∈ L^1(ℝ^n)$, the function \[ \hat{f}(ξ) = \int_{ℝ^n} f(x) e^{-2π\imath x · ξ} \dif x \] is in $C_0^0(ℝ^n)$ (that is, continuous and vanishing at infinity) and we have the pointwise bound \[ \norm{\hat{f}}_{L^∞} ≤ \norm{f}_{L^1} \]
\end{prop}

\begin{proof}

\proofpart{Continuity}

For the continuity, we can see that for a succession $\set{ξ_n}_{n ∈ ℕ} ⊂ ℝ^n$ with limit $ξ$ we have \[ \lim_{n \to ∞} \hat{f}(ξ_n) = \int_{ℝ^n} \lim_{n \to ∞} f(x) e^{-2π\imath x · ξ_n} \dif x\] where we have used the \nref{thm:DominatedConvergence} ($\abs{f(x) e^{-2π\imath x · ξ}} ≤ \abs{f(x)}$). As the exponential is continuous, $e^{-2π\imath x · ξ_n} \to e^{-2π\imath x · ξ}$ and then $\hat{f}(ξ_n) \to \hat{f}(ξ)$ and thus $\hat{f}$ is continuous.

\proofpart{Vanishing at infinity}

We can approximate $f$ as much as we want by a $g ∈ \schwartz$ (\fref{prop:SchwartzLpDensity}), and then we can use \fref{prop:SchwartzFourierItself} to see that the Fourier transform of $g$ must vanish at infinity. A little bit better: for any $ε > 0$, choose $g ∈ \schwartz$ such that $\norm{f - g}_1 < \sfrac{ε}{2}$ and $r > 0$ such that for $\abs{ξ} > r$ we have $\abs{\hat{g}(ξ)} < \sfrac{ε}{2}$
\begin{align*}
\hat{f}(ξ)
	&= \int_{ℝ^n} (f(x) - g(x) + g(x)) e^{-2π\imath x · ξ} \dif x \\
	&≤ \int_{ℝ^n} (f(x) - g(x)) e^{-2π\imath x · ξ} \dif x
		+ \int_{ℝ^n} g(x)e^{-2π\imath x · ξ} \dif x \\
	&≤ \norm{f(x) - g(x)}_{1} \norm{e^{-2π\imath x · ξ}} + \hat{g}(ξ) \\
	&≤ ε
\end{align*} when $\abs{ξ} \to ∞$.

\proofpart{Supremum bound $\norm{\hat{f}}_∞ ≤ \norm{f}_1$}

Just move absolute values inside of the integral.
\end{proof}

So for now we have proven that the Fourier transform works from $L^1$ to $L^∞$ and from $L^2$ to $L^2$. It seems that it maps $L^p$ spaces to their conjugate exponent ones. For that proof we will use the following theorem.

\begin{theorem}[Riesz-Thorin\IS theorem] \label{thm:RieszThorin} Let $1 ≤ p_0, p_1, q_0, q_1 ≤ ∞$ and assume $\meas$ is a measure space. Assume that $T$ is a linear operator from the simple functions\footnote{Defined as linear combination of indicator functions of measurable sets, that is $f(x) = \sum_{n = 1}^N a_n \ind_{A_n} (x)$ with $A_n ∈ \mathcal{X}$.} on $X$ to measurable functions on $X$, satisfying \begin{align*}
\norm{T(f)}_{L^{q_0}(X)} ≤ A_0 \norm{f}_{L^{p_0}(X)} \\
\norm{T(f)}_{L^{q_1}(X)} ≤ A_1 \norm{f}_{L^{p_1}(X)}
\end{align*} for all simple functions $f$.

Then, for any $p ∈ [p_0, p_1]$ with $\frac{1}{p} = \frac{θ}{p_0} + \frac{1-θ}{p_1}$ with $θ ∈ [0,1]$ we have \[ \norm{T(f)}_{L^q(x)} ≤ A_0^θ A_1^{1-θ} \norm{f}_{L^p(X)}\] with $q$ defined as $\frac{1}{q} = \frac{θ}{q_0} + \frac{1-θ}{q_1}$.
\end{theorem}

Before going to the proof of this, we will see its application to the Fourier transform.

\begin{corol} \label{crl:FourierTransformP12} The Fourier transform on $ℝ^n$ is a linear operator $\appl{\fourier}{L^p}{L^q}$ with $\frac{1}{q} + \frac{1}{p} = 1$ when $1 ≤ p ≤ 2$. Moreover, we have \[ \norm{\hat{f}}_{L^q} ≤ \norm{f}_{L^p} \quad p ∈ [1,2]\]
\end{corol}

\begin{proof}
Apply  \nref{thm:RieszThorin} with $p_0 = 1, q_0 = ∞$ and $p_2 = q_2 = 2$.
\end{proof}

\subsubsection{Riesz-Thorin theorem proof}

The proof of Riesz-Thorin is not trivial, and we will need some technical ingredients from, surprise, complex analysis.

\begin{lemma}[Hadamard\IS three lines lemma] Let $F$ be a complex analytic function on the strip $S ≝ \set{x ∈ ℂ \tq 0 < \Re z < 1}$ extending continuously and boundedly to the closure $\adh{S}$. Asssume the bounds \begin{align*}
\Re z = 0 &\implies \abs{F(x)} ≤ B_0 \\
\Re z = 1 &\implies \abs{F(x)} ≤ B_1
\end{align*} for two constants $B_0, B_1 > 0$. Then we have \[ \Re z = θ \implies \abs{F(z)} ≤ B_0^{1-θ} B_1^θ \] for any $θ ∈ [0,1]$.
\end{lemma}

\begin{proof} This is an application of the maximum modulus principle. Define \[ f(z) ≝ F(z) · (B_0^{1-z} B_1^z)^{-1}\]

Observe that $\abs{(B_0^{1-z} B_1^z)^{-1}} ≤ \max \set{\inv{B_0}, \inv{B_1}}$ if $\Re z ∈ [0,1]$ and so $f(z)$ is also bounded on $\adh{S}$.

Moreover, letting $f_ε (z) ≝ f(z) e^{ε(z^2 - 1)}$ for small $ε > 0$ and assuming $z = x + \imath y$, then \[ \abs{f_ε(z)} = \abs{f(z)} e^{ε(x^2 - y^2 - 1)}\] which converges to zero as $\abs{y} \to ∞$ while $x ∈ [0,1]$. We also have $\abs{f_ε(z)} ≤ 1$ if $x = 0,1$. Now, pick $y_0 > 0$ large enough so that $\abs{f_ε(z)} ≤ 1$ when $\abs{y} ≥ y_0$.

Then, by the maximum modulus principle and since the boundary values on the rectangular box $0 ≤ x ≤ 1, \abs{y} ≤ y_0$ are at most 1, we infer $\abs{f(z)} ≤ 1$ for any $z ∈ \adh{S}$ when $ε \to 0$.
\end{proof}

Now we can go on to the proof of Riesz-Thorin.

\begin{proof}[\nref{thm:RieszThorin}] First, define $p$ and $q$ as in the theorem:
\begin{align*}
\frac{1}{p} &= \frac{θ}{p_0} + \frac{1-θ}{p_1} \\
\frac{1}{q} &= \frac{θ}{q_0} + \frac{1-θ}{q_1}
\end{align*} with $θ ∈ (0,1)$.

We will separate the proof in two cases: first, when $p_0, p_1, q_0, q_1$ are strictly between $1$ and $∞$, and a second case when they are not.

\proofpart{$p_0, \dotsc, q_1 ≠ 1, ∞$}

Let's consider a simple function of the form \[ f(x) = \sum_{k = 1}^M a_k e^{\imath α_k} \ind_{A_k} (x)\] with $A_k ∈ \mathcal{X}$ disjoint sets and $a_k ∈ ℝ^+$.

% TODO: Complete this. Try to see some proof that is more clear than the crap on the lecture.

\end{proof}

\subsection{Convergence of the Fourier transform}

We have not answered yet the question of convergence of the Fourier transform. We saw with the \fref{crl:FourierTransformP12} that if we have $f ∈ L^p$ with $1 ≤ p ≤ 2$, its Fourier transform is well defined and the integrals have bounded. We can try to see if the integral converges in the $L^p$ sense. That is, whether
\[ \lim_{N \to ∞} \norm{\int_{\abs{ξ} ≤ N} \hat{f}(ξ) e^{2π\imath x · ξ} \dif ξ - f(x) }_{L^p(ℝ^n)} \qeq 0 \]

For that we would need to have that the function \[ \inv{\fourier}_N(f) (x) = \int_{\abs{ξ} ≤ N} \hat{f}(ξ) e^{2π\imath x · ξ} \dif ξ \] is of class $L^p$, which for now we have only assured for $p = 2$. Turns out that the answer depends crucially on the dimension, and we will only have good results for $n = 1$:

\subsubsection{Case $ℝ^1$, Hilbert transform}

For answering this question, we will introduce the Hilbert transform.

\begin{defn}[Hilbert\IS transform] Let $f ∈ C_0^∞(ℝ)$ and $ε > 0$. The, we can define \( \label{eq:HilbertTransEpsilon} H_ε f(x) ≝ \int_{-∞}^{-ε} \frac{f(x-y)}{y} \dif y + \int_ε^∞ \frac{f(x)-y}{y} \dif y = \int_ε^∞ \frac{f(x-y) - f(x + y)}{y} \dif y \) and \[ Hf(x) ≝ \lim_{ε \to 0} H_ε f(x) \]
\end{defn}

The Hilbert transform is specially interesting for its relations to the Fourier transform, specifically the following one.

\begin{lemma} Let $f ∈ C_0^∞(ℝ)$. Then we have\footnote{Recall that $\sign(ξ) = \begin{cases} 1 & ξ > 0 \\ 0 & ξ = 0 \\ -1 & ξ < 0\end{cases}.$} \[ \widehat{Hf}(ξ) = \int_ℝ Hf(x) e^{-2π\imath x · ξ} \dif x = -\imath π \sign(ξ) \hat{f}(ξ)\]
\end{lemma}

\begin{proof} Honestly I'm not sure about the $P.V.$ integral thing.
\end{proof}

\begin{corol} The Hilbert transform preserves the $L^2$ norm up to a constant multiple: \[ \norm{Hf}_{L^2(ℝ)} = π \norm{f}_{L^2(ℝ)}\]
\end{corol}

\begin{proof} Use \nref{thm:Plancherel} in conjuction wiht the previous lemma.
\end{proof}

Why is this interesting? We can see that we can express the indicator function as \[ \ind_{[-N, N]} (ξ) = \frac{1}{4} \left(\sign(N-ξ) + 1\right) · \left(\sign(N + ξ) + 1\right) \qquad ξ ∉ \set{\pm N} \] and furthermore
\begin{align*}
\sign(ξ - N) \hat{f}(ξ) &= \fourier\left(\frac{\imath e^{\imath N x}}{π} H(e^{-\imath Nx} f)\right) (ξ) \\
\sign(ξ + N) \hat{f}(ξ) &= \fourier\left(\frac{\imath e^{-\imath N x}}{π} H(e^{\imath Nx} f)\right) (ξ) \\
\end{align*} so that the operator \[ \inv{\fourier}_Nf(x) ≝ \int_{\abs{ξ} ≤ N} \hat{f}(ξ) e^{2π\imath x · ξ} \dif x \] will be $L^p(ℝ)$ bounded uniformly in $N$ if the Hilbert transform is $L^p$ bounded too.

\chapter{Hilbert transform}

\begin{theorem} If $1 < p < ∞$ and $f ∈ L^p(\crc)$, then \[ \norm{S_N f -f}_{L^p(\crc)} \convs[][N][∞] 0 \]
\end{theorem}

\begin{proof} Applying \fref{prop:FourierSeriesConvLp}, we only need to prove that the $S_N$ operator is uniformly bounded. We can start by writing
\[S_Nf = \int_{-\sfrac{1}{2}}^{\sfrac{1}{2}} \frac{\sin \left((2N + 1) π (x- y)\right)}{\sin \left(π(x - y)\right)} f(y)  \dif y \]

We can consider an alternative operator \[ \tilde{H}_N f ≝ \int_{-\sfrac{1}{2}}^{\sfrac{1}{2}} \frac{\sin \left((2N + 1) π (x- y)\right)}{π(x - y)} f(y)  \dif y\] and we claim that $\norm[0]{S_N - \tilde{H}_N} ≤ C$, with $C$ independent of $N$.

In order to see that, we can operate
\[
S_N - \tilde{H_N})f = \int_{-\sfrac{1}{2}}^{\sfrac{1}{2}} \underbracket{\sin  \left((2N + 1) π (x- y)\right) · \left(\frac{1}{\sin π(x -y)} - \frac{1}{π(x -y)} \right)}_{L_N} f(y) \dif y
\] and by Hölder inequality, we see that $\norm[0]{(S_N - \tilde{H}_N)f}_{L^p} ≤ \norm{L_N}_{∞} \norm{f}_p$ so we only need to bound the $L_N$ function. But it is easy to see as $\sin$ is bounded and $\lim_{x\to 0} \frac{1}{\sin x} - \frac{1}{x} = 0$, so everything is bounded (we are in a bounded domain).

Now we need to show $\norm{\tilde{H}_Nf}_p ≤ C \norm{f}_{L^p}$, and we will do it by a density argument. We will choose $f ∈ C_0^∞(\crc)$, bound the integral and then use density to approximate for any given $f ∈ L^p$.

First, we can rewrite the operator as\footnote{In this case $\pm x \equiv + x - x $ to avoid writing too many terms.} \begin{align*}
\tilde{H}_N f &=
	\pm \frac{1}{2\imath} \int_{-\sfrac{1}{2}}^{\sfrac{1}{2}} \frac{e^{\pm \imath (2N + 1) π (x-y)}}{π (x-y)} f(y) \dif y = \\
	&= \pm \frac{e^{\pm \imath(2N + 1)πx}}{2π \imath} \int_{-\sfrac{1}{2}}^{\sfrac{1}{2}} \frac{1}{x-y} e^{\mp \imath (2N + 1)πy} f(y) \dif y
\end{align*}

Now the integrand is the Hilbert transform of $g(y) = e^{\mp \imath (2N + 1)πy} f(y)$, so that $\norm{Hg}_{L^p(ℝ)} ≤ C \norm{g}_{L^p(ℝ)} = C \norm{f}_{L^p(-\sfrac{1}{2}, \sfrac{1}{2})}$.

And this finishes the proof because something I didn't catch. But yes.
\end{proof}

\chapter{Calderon-Zygmund operator}

The Hilbert transform seemed like a useful thing to have. However, we have only defined it for $ℝ$ and not for $ℝ^n$. It turns out that we can give an ``extension'', which is called the Calderon-Zygmund operator, by using the property of the Hilbert transform on the Fourier side, which was \[ \widehat{Hf}(ξ) = - π\imath \sign (ξ) \hat{f}(ξ) = - π\imath \frac{ξ}{\abs{ξ}} \hat{f}(ξ) \] and then we could define something as \[ \widehat{R_j f} (ξ) ≝ C_n \frac{ξ_j}{\abs{ξ_j}} \hat{f}(ξ) \]

\begin{defn}[Calderon-Zygmund kernel][Kernel\IS Calderon-Zygmund] \label{def:CalderonZygmundKernel} A function $K ∈ C^∞(ℝ^n \setminus\set{0})$ is called a Calderon-Zygmund kernel if $K$ satisfies
\begin{enumerate}
\item \label{prp:CZAss1} $\abs{K(x)} ≤ B \abs{x}^{-n} \quad ∀x ∈ ℝ^n, \, B > 0 $
\item \label{prp:CZAss2} $\abs{∇K(x)} ≤ B \abs{x}^{-n - 1}  \quad ∀x ∈ ℝ^n, \, B > 0$
\item \label{prp:CZAss3} $\int\limits_{r ≤ \abs{x} ≤ s} K(x) \dif x = 0 \quad  ∀r,s > 0 $
\end{enumerate}
\end{defn}

One can see that the Hilbert transform is a case of a Calderon-Zygmund kernel with $K_H(x) = \frac{1}{x}$.

We can also prove a first lemma that will become very useful when proving the boundedness of the operator.

\begin{lemma}[Hormander\IS condition] \label{lem:HormanderCond} The second assumption \eqref{prp:CZAss2} of a \nref{def:CalderonZygmundKernel} implies that \[ \int_{\abs{x} > 2\abs{y}} (K(x) - K(x-y)) \dif x  ≤ CB \quad ∀ y ≠ 0\]
\end{lemma}

\begin{proof} We can write \[ K(x) - K(x-y) = \int_0^1 ∇K (x - ty) · (-y) \dif t \] so that by \eqref{prp:CZAss2}
\[ \norm{∇K(x - ty)}_{L^∞} ≤ \frac{B}{\abs{x - ty}^{n+1}} ≤ \frac{B2^{n+1}}{\abs{x}^{n+1}} \] if $\abs{x} ≥ 2\abs{y}$.

Therefore we have \[
\int_{\abs{x} > 2\abs{y}} (K(x) - K(x-y))
	≤ \int_{\abs{x} > 2\abs{y}} \abs{y} \frac{B2 ^{n+1}}{\abs{x}^{n+1}} \dif x
\] which is perefctly bounded.
\end{proof}

\begin{defn}[Calderon-Zygmund operator][Operator\IS Calderon-Zygmund] \label{def:CalderonZygmundOperator} Given a \nref{def:CalderonZygmundKernel} $K$, we can define the Calderon-Zygmund operator for $f ∈ \schwartz$ as \[ (Tf) (x) ≝ \lim_{ε \to 0+} \int_{\abs{x - y} ≥ ε} K(x -y) f(y) \dif y \]
\end{defn}

First question is, of course, whether that limit is well-defined.

\begin{lemma} $T$ is well defined, that is, the limit exists for any fixed $x ∈ ℝ^n$.
\end{lemma}

\begin{proof} First we do a change of variable \[ \int_{\abs{x - y} ≥ ε} K(x -y) f(y)  = \int_{\abs{y} ≥ ε} K(y) f(x - y) \] and we will separate the domain of integration in two parts: one with $\abs{y} ≥ 1$ (which can cause problems with boundedness of the integral) and $1 ≥ \abs{y}  ≥ ε$ (which can cause problems due to singularities of $K(0)$).

For the first part, we only need to see that $f$ is a Schwartz function and decays fast enough.

For the second part, we can add a constant part (w.r.t $y$) because $\int_{1 ≥ \abs{y} ≥ ε} K(x) \dif x = 0$ \eqref{prp:CZAss3}, so that
\begin{align*}
\int\limits_{1 ≥ \abs{y} ≥ ε} K(y) f(x - y) \dif y
	&= \int\limits_{1 ≥ \abs{y} ≥ ε} K(y) (f(x - y) - f(x)) \dif y = \\
	&= \int\limits_{1 ≥ \abs{y} ≥ ε} B \abs{y}^{-n} \norm{∇f}_{L^∞} \abs{y} \dif y ≤ \\
	&≤ C \norm{∇f}_{∞} \int_ε^1 \dif \abs{y} ≤ C
\end{align*}
\end{proof}

Now we will be interested in the boundedness of this operator.

\begin{prop} \label{prop:CaldZygL2Bound} If $T$ is a Calderon-Zygmund operator, then it's bounded in $\linapp[L^2][L^2]$.
\end{prop}

\begin{proof} Assume $f ∈ \schwartz$. We want to show that \[ \norm{Tf}_{L^2(ℝ^n)} ≤ CB \norm{f}_{L^2(ℝ^n)}\]

We introduce the following ``restricted'' operator
\[ T_{r,s} f(x) ≝ \int_{\bola_{r,s}} K(y) f(x -y) \dif y = f * \left(\ind_{\bola_{r,s}} · K\right)\] where $\bola_{r,s} ≝ \bola_s(0) \setminus \bola_r (0) \equiv \set{y ∈ ℝ^n \st s ≥ \abs{y} ≥ r}$.

We will prove that this operator is $L^2$-bounded by a constant independent of $r$ and $s$, so that proves the boundedness of $T$ by taking the limits on both variables.

As the Fourier transform is an isometry on $L^2$, we can calculate the norm there to have the bound \[ \norm{T_{r,s} f}_{L^2} = \norm{\widehat{T_{r,s} f}}_{L^2} ≤ \norm{\hat{f}}_{2} \norm{\fourier\left(\ind_{\bola_{s,r}} · K \right)}_{∞} \]

In this case, the Fourier transform will be defined as \[ \widehat{T_{r,s}f}(ξ) = \hat{f}(ξ) · \fourier\left(\ind_{\bola_{r,s}}(y) K (y)\right) (ξ)\] which is well-defined because $\ind_{\bola_{r,s}} · K$ is smooth enough and bounded.

We therefore need to compute the $L^∞$ norm of $\fourier(\ind_{\bola_{s,r}} K)$. Now we can divide the integral of the Fourier transform in two intervals of $\abs{y}$: $I_1 = [r, η_1]$ and $I_2 = [η_2, s]$ with $η_1 = \min \set[0]{s, \inv{\abs{ξ}}}$ and $η_2 = \max \set[0]{r, \inv{\abs{ξ}}}$.

Now we estimate the integral in the first interval, using again the trick of adding a constant w.r.t $y$ because the integral of $K$ is zero over that domain (\fref{prp:CZAss3})
\begin{align*}
\abs{\int_{I_1} K(y) (e^{-2π\imath y · ξ} - 1) \dif y}
	&≤ C \int_{I_1}  \abs{K(y)} \abs{y} \abs{ξ} \dif y \\
	&≤ C \int_{I_1}  \abs{y}^{-n + 1} \abs{ξ} \dif y  \\
	&≤ C \int_r^{η_1} \abs{ξ} \dif \abs{y} ≤ \\
	&≤ C \abs{ξ} η_1 ≤ 1
\end{align*}

For the second interval we will exploit the \nref{lem:HormanderCond}.
\begin{align*}
\int\limits_{η_2 ≤ \abs{y} ≤ s} K(y) e^{-2π\imath y · ξ} \dif y
	&= - \int_{η_2 ≤ \abs{y} ≤ s} K(y) e^{-2π\imath\left(y + \frac{ξ}{2\abs{ξ}^2}\right) · ξ} \dif y = \\
	&= \frac{1}{2} \left[ \int_{η_2 ≤ \abs{y} ≤ s} K(y) e^{-2π\imath ξ y} \dif y - \int\limits_{η_2 ≤ \abs{y - \frac{ξ}{2 \abs{ξ}^2}} ≤ s} K\left(y - \frac{ξ}{2 \abs{ξ}^2}\right) e^{-2πξ y} \dif y \right]
\end{align*}

I'm not copying more of this bullcrap.

\end{proof}


\section{Calderon-Zygmund decomposition of a function}

In this section we will introduce a fundamental tool in harmonic analysis, which will allow us to decompose general functions $f ∈ L^1(ℝ^n)$ in ``good parts'' (bounded) and ``bad parts'' restricted to a controlled, small set.

\begin{theorem}[Calderon-Zygmund\IS theorem] Let $f ∈ L^1(ℝ^n)$ and fix $λ > 0$. Then we can write \[ f = g + b \] wth $\abs{g} ≤ λ$ almost everywhere and $b = \sum_{Q ∈ \mathcal{Q}} \ind_Q f$ with $\mathcal{Q}$ a disjoint collection of cubes $Q ⊂ ℝ^n$ and such that \[ λ < \fint_Q \abs{f(x)} \dif x < 2^n λ \] where $μ$ is the measure on $ℝ^n$.

Moreover, we can bound the support of $b$ by \[ \left|\bigcup_{Q ∈ \mathcal{Q}} Q\right| ≤ \inv{λ} \norm{f}_{L^1(ℝ^n)} \]
\end{theorem}

\begin{proof}
\begin{wrapfigure}[10]{R}{0.4\textwidth}
\centering
\vspace{-5pt}
\inputtikz{CubePartition}
\caption{A partition of $ℝ^n$ in cubes with edge length $2^l$.}
\label{fig:CubePartition}
\end{wrapfigure}

The proof is a constructive-inductive process to build the collection of ``bad cubes''. Denote by $\mathcal{D}_l$ the set of cubes of length $2^l$ that partition $ℝ^n$, with edges parallel to the coordinate axes as seen in \fref{fig:CubePartition}.

We start by choosing $l_* ∈ ℤ$ large enough such that \[ 2^{-nl_*} \int_ℝ^n \abs{f} \dif x ≤ λ\] and therefore $\fint_Q \abs{f} ≤ λ$ for any cube $Q ∈ \mathcal{D}_{l_*}$.

Now, for each of those cube we look at its children, that is, those cubes $Q' ∈ \mathcal{D}_{l_* - 1}$ with length $l_* - 1$ such that $Q' ⊂ Q$. For those children $Q'$ we have two options: either $\fint_{Q'} \abs{f} > λ$ or it's $≤ λ$. In the first case we have a ``bad cube'', so we add it to the collection $\mathcal{Q}$. In the second case, we continue with the children of $Q'$ with length $l_* - 2$.

Now set the decomposition as $b$ taking the values of $f$ on the ``bad cubes'' where the process stopped, so that \[ b ≝ \sum_{Q ∈ \mathcal{Q}} \ind_Q f\] and $g$ as the remaining part: $g = f - b$.

Now we start with the proofs of the bounds. If $x ∈ ℝ^n \setminus ∪_\mathcal{Q} Q$, then by construction there is a sequence of shrinking cubes $Q_i \to \set{x}$ that satisfy $\fint_{Q_i} \abs{f} ≤ λ$. By the \nref{thm:DiffLebesgue}, we have that $\lim_{i \to ∞} \fint_{Q_i} \abs{f} = \abs{f(x)}$ for almost every $x ∈ ℝ^n$ and therefore we have our first bound $\abs{g(x)} ≤ λ$ almost everywhere.

For the bound on the measure of the cubes, we note that if $Q ∈ \mathcal{Q}$ is a ``bad cube'', then its parent $\tilde{Q}$ that contains it and has twice the edge length is, by definition, such that $\fint_{\tilde{Q}} \abs{f} ≤ λ$ and so we have \[ \fint_Q \abs{f} ≤ 2^n \fint_{\tilde{Q}} \abs{f} ≤ 2^n λ \] and therefore we have that
\end{proof}

This theorem allows the proof of a proof on a weak $L^1$ bound for the Calderon-Zygmund operator.

\begin{theorem} Let $T$ be a \nref{def:CalderonZygmundOperator} given by \[ Tf(x) = \int_{ℝ^n} K(x -y) f(y) \dif y \] for $f ∈ \schwartz$. Then we have the weak $L^1$ bound \[ \abs{\set{x ∈ ℝ^n \st \abs{Tf(x)} > λ}} ≤ CB \inv{λ} \norm{f}_{L^1(ℝ^n)} \quad ∀λ > 0 \] for a suitable universal constant $C$ and $B$ as in the definition of the Calderon-Zygmund kernel.
\end{theorem}

\begin{proof} We can assume without loss of generality that $B = 1$ (if not, replace $T$ by $\inv{B}T$). Given a fixed $λ > 0$ and $f ∈ \schwartz$, we consider the Calderon-Zygmund decomposition of $f = g + b$ associated to λ and will modify it a bit. Define \[ φ ≝ \sum_{Q ∈ \mathcal{Q}} \ind_Q(x) \fint_Q f(y) \dif y \] so that $f = f_1 + f_2$ with $f_1 = g + φ$, $f_2 = b - φ$.

From here we can make several observations. As $g$, $b$ and $φ$ are bounded in $L^1(ℝ^n)$, we have that $\norm{f_1}_{L^1} ≤ \norm{f}_{L^1}$ and $\norm{f_2}_{L^1} ≤ 2 \norm{f}_{L^1}$. Finally, $f_2$ has vanishing average over each ``bad cube'' $Q ∈ \mathcal{Q}$: \[ \int_Q f_2(x) \dif x = \int_Q \left(f(x) - \fint_Q f(y) \dif y \right) \dif x = \int_Q f(x) \dif x - \abs{Q} \fint_Q f(y) \dif y = 0 \]

Now, as the Calderon-Zygmund operator is linear we can consider the decomposition $Tf = Tf_1 + Tf_2$, and therefore \[ \set{x ∈ ℝ^n \st \abs{Tf(x)} > λ} ⊂ \set{x ∈ ℝ^n \st \abs{Tf_1(x)} > \sfrac{λ}{2}} ∪ \set{x ∈ ℝ^n \st \abs{Tf_2(x)} > \sfrac{λ}{2}}\] and so it will suffice to bound only each set for the components as \[ \abs{\set{x ∈ ℝ^n \st \abs{T f_j(x)} > λ}} ≤ C \inv{λ} \norm{f}_{L^1} \quad j = 1,2\]

\proofpart{Bound for $f_1$}

We will use the fact that $T$ is an $L^2$ bounded operator (\fref{prop:CaldZygL2Bound}). First, observe that if $\abs{T f_1(x)} > λ$ then $(Tf_1(x))^2 > λ^2$ and then we can apply \nref{thm:MarkovIneq}:
\begin{multline*} \abs{\set{x ∈ ℝ^n \st \abs{T f_1(x)} > λ}} = \abs{\set{x ∈ ℝ^n \st (T f_1(x))^2 > λ^2}} ≤ \\ ≤ λ^{-2} \int_{ℝ^n} (Tf_1)^2 = λ^{-2} \norm{Tf_1}^2_{L^2} ≤  λ^{-2} C\norm{f_1}^2_{L^2} \end{multline*}

We only need to pass from the $L^2$ norm to the $L^1$. Observe that $f_1$ is bounded as \[ \abs{f_1} ≤ \max \set{\abs{g}, \sup_{Q ∈ \mathcal{Q}} \fint_Q \abs{f}} ≤ 2^n λ\] and therefore \[ \norm{f_1}^2_{L^2} = \int_{ℝ^n} \abs{f_1} · \abs{f_1} ≤ 2^nλ \int_{ℝ^n} \abs{f_1} ≤ 2^nλ \norm{f}_{L^1} \] and so we get as desired \[\abs{\set{x ∈ ℝ^n \st \abs{T f_1(x)} > λ}} ≤ C_1 \inv{λ} \norm{f}_{L^1} \]

\proofpart{Bound for $f_2$}

This one gets a little bit more complicated.

\end{proof}

\chapter{BMO functions}

\chapter{Fourier multipliers}

\appendix

\chapter{Useful theorems}

\section{Measure theory and real analysis}

\begin{theorem}[Dominated convergence\IS theorem] \label{thm:DominatedConvergence} Let $\set{f_n}_{n ∈ ℕ}$ be a series of functions such that $f_n \convs f$ almost everywhere. If there exists an integrable, non-negative function $g$ such that $\abs{f_n} ≤ g$, then \[ \int \lim_{n \to ∞} f_n \dif μ = \lim_{n \to ∞} \int f_n \dif μ\]
\end{theorem}

\begin{theorem}[Markov inequality][Inequality\IS Markov] \label{thm:MarkovIneq} Let \meas be a measure space and $\appl{f}{X}{ℝ}$ a measurable function. Then, for any $ε > 0$ we have that \[ μ\left(\set{x ∈ X \st \abs{(x)} ≥ ε}\right) ≤ \frac{1}{ε} \int_X \abs{f} \dif μ \] or, in other words, the set of points where $f$ has high values gets smaller the higher that value is.
\end{theorem}

\begin{theorem}[Lebesgue\IS differentiation theorem] \label{thm:DiffLebesgue} \citep[Theorem II.22]{ApuntesVariableReal} Let $\appl{f}{ℝ^N}{ℝ}$ be a locally integrable function. Then, for almost every $x ∈ ℝ^N$, we have that \[ \lim_{r \to 0} \fint_{E_r(x)} f(y) \dif y = f(x) \] for every family of sets $\set{E_r}$ that shrinks nicely to $x$.
\end{theorem}

Note that we use the notation $\fint_A f ≝ \frac{1}{\abs{A}} \int_A f$. For the ``shrinks nicely'', we give the following technical definition:

\begin{defn}[Nicely shrinking sets] A family of sets $\set{E_r}_{r > 0}$ is said to shrink nicely to $x$ if and only if $E_r ⊂ \bola_r(x)$ and there exists a constant $α > 0$ independent of $r$ such that $\abs{E_r} > α\abs{\bola_r}$.
\end{defn}

In other words, this allows to take into account not only balls of radius $r$ but other shrinking sets that behave more or less in the same way.

\section{Functional analysis}

\begin{theorem}[Banach-Steinhaus\IS uniform boundedness theorem] \citep[Theorem II.8]{ApuntesAnalisisFunc} \label{thm:BanachSteinhaus} Let $\set{T_α}_{α ∈ A}$ a subset of the space of continuous linear applications $\linapp$ between $X$ and $Y$, where $X$ is a Banach space and $Y$ is a normed space. Then, either the linear applications $T_α$ are uniformly bounded (that is, $∃ C < ∞$ such that $\norm{T_α}_{\linapp} ≤ C$ for all $α ∈ A$) or either there is a certain $G_δ$ set\footnote{Countable intersection of open set} dense in $X$, denoted by $B$, such that \[ \sup_{α ∈ A} \norm{T_α(x)}_Y = ∞ \quad ∀x ∈ B\]
\end{theorem}


\chapter{Exercises}
\input{tex/HarmonicAnalysis_Exerc.tex}
\backmatter

\nocite{muscalu2013classical}
\bibliography{../EPFLNotes.bib}

\printindex
\end{document}
