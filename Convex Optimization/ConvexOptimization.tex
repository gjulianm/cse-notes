\documentclass[palatino, shortheader, notitlepage, nochapters]{reportdoc}

\title{Convex Optimization \\ A quick Summary}
\author{Guillermo Julián Moreno}
\date{16/17 - Spring semester}

% Additional packages

% --------------------

\begin{document}
\maketitle

\section{Linear programming}

The basic idea of linear programming is to maximize a target function $f(\vx)$ subject to certain constraints. The formulation is the following.

\begin{defn}[Linear programming problem][Problem\IS Linear programming] \label{def:LinearProgProb} A Linear Programming problem consists in, given $\vc ∈ ℝ^N$, $\vb ∈ ℝ^M$ and $\mA ∈ ℝ^{M × N}$, finding the value of $\vx ∈ ℝ^N$ that minimizes $\vc^T \vx$ subject to $\mA \vx ≤ \vb$.
\end{defn}

We will define the \concept{Constraint\IS set} as the set $C = \set{\vx ∈ ℝ^N \st \mA \vx ≤ \vb}$, that is, the points that satisfy the constraints. Of course, we want this to be nonempty and possibly bounded. The solution to a linear problem always lies in the extrema of the constraint set.

\subsection{Duality}

We can also define a dual problem via the Lagrangian.

\begin{defn}[Lagrangian] \label{def:Lagrangian} For the problem of minimizing a function $f_0(\vx)$ subject to
\begin{align*}
f_i(\vx) &≤ 0  & i = 1, \dotsc, M \\
h_i(\vx) &= 0  & i = 1, \dotsc, P
\end{align*} with $\vx ∈ D ⊆ ℝ^N$, we can define the Lagrangian as
\begin{align*}
\appl{L}{D × ℝ^M × ℝ^p&}{ℝ} \\
\vx, \vec{λ}, \vec{ν} &\longmapsto f_0(\vx) + \sum_{i = 1}^M λ_i f_i(\vx) + \sum_{i = 1}^P ν_i h_i(\vx)
\end{align*}
\end{defn}

This function has the following funny property: if $\vx ∈ D$ satisfies the constraints and $\vec{λ} ≥ 0$, then it's clear that $L(\vx, \vec{λ}, \vec{ν}) ≤ f_0(\vx)$. So, it can be said that the lagrangian is an inferior bound of the optimal value of $f_0$. For that, we will introduce the dual function.

\begin{defn}[Dual\IS function] The dual function associated to the \nref{def:Lagrangian} is defined as \begin{align*}
\appl{g}{ℝ^M× ℝ^P&}{ℝ} \\
\vec{λ}, \vec{ν} &\longmapsto \inf_{\vx ∈ D} L(\vx, \vec{λ}, \vec{ν})
\end{align*}
\end{defn}

If the constraints are linear, we can see that $g(\vx, \vec{λ}, \vec{ν}) = -∞$ unless $f_0(\vx) + \vec{λ} F(\vx) + \vec{ν} H(\vx)$\footnote{I'm using notation $F(\vx) = (f_1(\vx), \dotsc, f_M(\vx))$ for shortness.} does not depend on $\vx$.

In the case of our \nref{def:LinearProgProb}, we have that \begin{align*}
L(\vx, \vec{λ}) &= \vc^T \vx + \vec{λ}^T (\mA \vx - \vb) \\
g(\vec{λ}) &= \inf_{x ∈ D} (\vc + \mA^T \vec{λ})^T \vx - \vb^T \vec{λ} = \begin{cases} - \vb^T \vec{λ} & \mA^T \vec{λ} + \vec{c} = 0 \\
- ∞ & \text{otherwise} \end{cases}
\end{align*}

As discussed before, we want to maximize that function so that we are as close as possible to that upper bound $f_0(\vx)$. In fact, we have following theorem.

\begin{theorem}[Strong duality theorem] Let $p^* ∈ ℝ$ the optimal value of the target function of a linear programming problem with dual function $g(\vec{λ}, \vec{ν})$. Then, for all $\vec{λ} ≥ 0$ and $∀ \vec{ν}$ we have that $g(\vec{λ}, \vec{ν}) = p^*$ if it is strictly feasible (that is, $f_i(\vx) < 0$).
\end{theorem}

We can also introduce the dual linear programming problem.

\begin{defn}[Dual\IS linear problem] Given a \nref{def:LinearProgProb}, its dual consists of maximizing $- \vb^T \vec{λ}$ subject to $\mA^T \vec{λ} + \vc = 0$ and $\vec{λ} ≥ 0$.
\end{defn}

Also, if strong duality holds and $f_0(\vx^*) = g(\vec{λ}^*, \vec{ν}^*) ≤ f_0(\vx^*)$, then we have that $\vx^*$ minimizes $L(\vx, \vec{λ}^*, \vec{ν}^*)$ and $λ_i^* f_i(\vx^*) = 0$ (\concept{Complementary slackness}) so one of the two factors must be zero.

For duality, we can define the following

\begin{defn}[Convex\IS conjugate] Given $\appl{f}{X}{ℝ}$, its convex conjugate is given by
\begin{align*}
\appl{f^*}{X^*&}{ℝ} \\
y &\longmapsto \sup_{x ∈ X} \pesc{y, x} - f(x)
\end{align*}
\end{defn}

For example, if $f(x) = - \log x$ then $f^*(y) = -1 - \log (-y)$ when $y < 0$ ($∞$ otherwise). If $f(\vx) = \frac{1}{2} \vx^T \mQ \vx$, then $f^*(\vy) = \frac{1}{2} \vy^T \mQ^{-1} \vy$. If our problem is minimizing $f_0(\vx)$ subject to $\mA \vx ≤ \vb$ and $\mC \vx = \vd$, then
\[ g(\vec{λ}, \vec{ν}) = \inf_{x ∈ D} f_0(\vx) + (\mA^T \vec{λ} + \mC^T \vec{ν})^T \vx - \vb^T \vec{λ} - \vd^T \vec{ν} = - f_0^*(- \mA^T \vec{λ} - \mC^T \vec{ν}) - \vb^T \vec{λ} - \vd^T \vec{λ} \]

\subsection{Sensitivity}

Suppose we have the problem of minimizing $f_0(\vx)$ such that $F(\vx) ≤ \vu$ and $H(\vx) = \vv$. The dual is maximizing $g(\vec{λ}, \vec{ν}) - \vu^T \vec{λ} - \vv^T \vec{ν}$ such that $\vec{λ} ≥ 0$. If we consider the optimal value $p^*$ as a function of $\vu, \vv$ then $\vec{λ} = - ∇_{\vu} p(0,0)$ and $\vec{ν} = - ∇_{\vv} p(0,0)$.

\subsection{Convexity}

Convex combination of $x_1, \dotsc, x_k$ is any point $x = \sum θ_i x_i$ with $\sum θ_i = 1$ and $θ_1 ≥ 0$. The convex hull of $S$ is all the convex combinations of points in $S$.

We might also study cones, sets $C$such that $λx ∈ C$ for all $λ  >0$, $x ∈ C$. Similarly, a conic combination is any point of the form $x = θ_1 x_1 + θ_2 x_2$ with $θ_1, θ_2 ≥ 0$.

Finite intersections of convex sets are convex. They are preserved under affine functions and their inverses, under perspective functions\footnote{$\appl{P}{ℝ^{N+1}}{ℝ}$ with $P(\vx, t) = \sfrac{\vx}{t}$.} and their inverses and under linear fractional functions and their inverses.

\begin{defn}[Convex function] A function $\appl{f}{D ⊆ ℝ^n}{ℝ}$ is convex if $D$ is convex and \[ f(θx + (1-θ)y) ≤ θf(x) + (1-θ) f(y)\] for any $x,y ∈ D$ and $θ ∈ [0,1]$. A function is strictly convex if the equality is strict.
\end{defn}

\begin{prop} A function $\appl{f}{X ⊆ ℝ^n}{ℝ}$ is convex if and only if the function \begin{align*}
\appl{g}{T&}{ℝ}  \\
t &\longmapsto f(x + tv)
\end{align*} with $T = \set{t ∈ ℝ \st x + tv ∈ X}$ is convex for any $x ∈ X$ and $v ∈ ℝ^n$.
\end{prop}

A function will also be convex if its hessian matrix of partial second derivatives is positive semidefinite. If $f$ is only once differentiable, then $f$ is convex if and only if $f(x) > f(y) + f'(y) (x-y)$.

Several combinations of convex functions are also convex. Not necessary to describe them, maybe that pointwise supremum is also convex, and that $f(x,y)$ convex for $(x,y) ∈ C$ convex set, then $g(x) = \inf_C f$ is also convex. Pointwise maximum of convex functions is convex.

Important things: any locally optimal function of a convex problem is globally optimal.

Some simple LPs:
\begin{itemize}
	\item Minimization of $\pesc{\vc, \vx}$ s.t. $\mA \vx = \vb$. If feasible and $\vc \perp \ker \mA$ then $\vc = \mA^T \vec{λ} + \hat{c}$ with $\mA \hat{c} = 0$. We then replace, if $c$ is not in the range of $\mA^T$ (that is, $\hat{\vc} ≠ 0$) then the problem is unbounded. If not, the optimal is $\vec{λ}^T\vb$.
	\item Minimization of $\vc^T \vx$ s.t. $\va^T \vx ≤ b$. This is always feasible, we decompose $\vx$ as a component parallel $\va λ$ and another $\hat{\vc}$ orthognola to $\va$. We then replace. If $λ > 0$ or $\hat{\vc} ≠ 0$, the problem is unbounded below. If $\hat{\vc} = 0$, then optimal value is $\vc^T \va \vb = λ \vb$.
	\item Minimization of linear function $\vc^T \vx$ over a rectangle $\vec{l} \preceq \vx \preceq \vu$. We can minimize over each component and as it's linear it's easy.
	\item Minimization $\vc^T \vx$ over the probability simplex $\ind^T \vx = 1$ with $x \succeq 1$. If we sort components of $\vc$ in increasing order we have $\vc^T \vx ≥ c_{\text{min}}$ because all sums 0. Which is obvious: we invest all in the one with highest investents.
\end{itemize}

\subsection{Karush-Kuhn-Tucker conitions}

For a problem with $f_i, h_i$ differentiable, the KKT conditions are the prima constraints $f_i(x) ≤ 0$, $h_i(x) = 0$, the dual constraints $λ ≥ 0$, the complementary slackness $λ_if_i(x) = 0$ and gradient of Lagrangian with respect to $x$ vanishes: \[ ∇_x f_0(x) + \sum λ_i ∇_x f_i(x) + \sum ν_i ∇_x h_i(x) = \]

If strong duality holds and $x, λ, ν$ are optimal, then they must satisfy KKT conditions.

Normally, for KKT conditions we will consider only complementary slackness, zero gradient and positiveness of the $\vec{λ}$. One can use those conditions to write the system and solve for the solution.

\section{Optimization algorithms}

\subsection{Unconstrained}

There are several possibilities of optimizations algorithms for minimizing a function $f(\vx)$ with $\vx ∈ D$.

\begin{itemize}
\item \textbf{Line search}: For each step, choose direction $Δ\vx ∈ D$, and from $t = 1$ set $t = βt$ ($β ∈ (0,1)$) until $f(\vx_k + tΔ\vx) < f(\vx) + α t ∇f(\vx) Δ\vx$ with $α ∈ (0,\sfrac{1}{2})$.
\item \textbf{Gradient descent}: Line search or choose $t$ exact.
\item \textbf{Steepest descent}: $Δ\vx = \argmin_{\norm{v} = 1} ∇f(\vx) · \vv$. Advantage is that we can select differnt norms.
\item \textbf{Newton step}: $Δx = - (∇(∇f(\vx)))^{-1} ∇f(x)$ (motivation minimization of second order approximation). We can add the Newton decrement $λ(x) = \sqrt{∇f(\vx) \inv{(∇^2f(\vx))} ∇f(x)}$ which is affine invariant and gives a stopping criterion on $\sfrac{λ^2}{2} ≤ ε$.
\end{itemize}

\subsection{Interior point methods}

We come back to the problem of minimizing $f_0(\vx)$ subject to $f_i(\vx) ≤ 0$ for $i = 1, \dotsc, m$ and $\mA \vx = \vb$.

We further assume $f_i ∈ C^2$ and convex, $\mA ∈ ℝ^{p×n}$ with full rank $p$, $p^*$ finite and attained and problem strictly feasible (constraints satisfied with strict inequality) so that we have strong duality.

We can approximate it as the problem of minimizing $f_0(\vx) + \sum χ_{ℝ^+} (f_i(\vx))$\footnote{$χ_A (x) = \begin{cases} ∞ & x ∈ A \\ 0 & x ∉ A \end{cases}$} which we can compute as minimizing \[ f_0(\vx) - \frac{1}{t} \sum_{i = 1}^m \log -f_i(\vx)\] subject to $\mA\vx = \vb$ as $- α \log x \convs[][α][0] χ_{ℝ^+}$.

Given the assumptions on $f_i$, the logarithmic barrier $φ(\vx) = - \sum \log -f_i(\vx)$ is convex and $φ ∈ C^2$ with
\begin{align*}
∇φ(\vx) &= \sum_{i=1}^m \frac{-1}{f_i(\vx)} ∇f_i(\vx) \\
∇^2φ(\vx)&= \sum_{i = 1}^m \frac{1}{f_i(\vx)^2} ∇f_i(\vx) \otimes ∇f_i(\vx) - \frac{1}{f_i(\vx)} ∇^2 f_i(\vx)
\end{align*}

Now we can define $\vx^*(t)$ as the optimal point for minimizing $tf_0(\vx) + φ(\vx)$ and define the central path as $\set{\vx^*(t) \st t > 0}$. This is related to duality:  $x$ is a point in the central path if there exists a $w$ such that \[ t ∇f_0(\vx) + \sum_{i=1}^m \frac{-1}{f_i(\vx)} ∇f_i(\vx) + \mA^T w = 0 \quad \mA \vx = \vb\] and therefore $\vx^*$ minimizes the Lagrangian
\[ L(\vx, \vec{λ}^*(t), \vec{ν}^*(t)) = f_0(\vx)  + \vec{λ}^* F_i(\vx) + \vec{ν}^*(t)^T(\mA\vx - \vb)\] with $\vec{λ}^*(t) = \frac{1}{-t F(\vx^*(t))}$ and $\vec{ν}^*(t) = w /t$.

This gives us the following steps for the barrier method: given $t_0 > 0$, $μ > 1$ and a tolerance $ε > 0$, we execute for iteration $k$
\begin{enumerate}
	\item Compute $\vx^*(t)$ by minimizing $tf_0 + φ$ subject to $\mA\vx = \vb$, usually with Newton's method starting at current $x_k$.
	\item Set $x_{k + 1} = x^*(t)$.
	\item Quit if $\frac{m}{t} < ε$.
	\item Set $t_{k + 1} = μ t_k$.
\end{enumerate}

The choice of $μ$ involves a tradeoff between outer and Newton iterations, typically $μ = 10-20$.

\subsection{Quadratic programming}

We will minimize here \[ \frac{1}{2} \vx^T \mP_0 \vx + \vq_0^T \vx + \vr_0 \] subject to $\frac{1}{2} \vx^T \mP_i \vx + \vq_i^T \vx + \vr_i ≤ 0$ and $\mA\vx = \vb$ with $\mP_i$ symmetric and positive definite. The feasible region is intersection of $m$ ellipsoids and an affine set.

We can also minimize $f^T \vx$ subject to $\norm{\mA_i \vx + \vb_i}_2 ≤ \vc_i^T \vx + d_i$ and $\mtr{F} \vx = \vg$. These are second-order SOC constraints, $(\mA_i \vx + \vb_i, \vc_i^T \vx + \vd_i)$ in a second-order cone in $ℝ^{n_i + 1}$. With $n_i = 0$ it's LP, with $c_i = 0$ it's quadratic constrained quadratic programming.

The dual of the SOCP can be obtained by changing the variable so the problem becomes minimizing $\vf^T \vx$ subject to \begin{align*}
\norm{\vy_i}_2 &≤ t_i & i = 1, \dotsc, m \\
\vy_i &= \mA_i \vx + \vb_i & i = 1, \dotsc, m \\
t_i &= \vc_i · \vx + d_i & & i = 1, \dotsc, m
\end{align*} with the lagrangian being
\begin{align*}
L(\vx, \vy, t, \vec{λ}, \vec{ν}, \vec{μ}) &= \left(\vc - \sum_{i=1}^m \left(\mA_i^T ν_i - μ_i c_i\right)\right)^T \vx + \sum_{i=1}^m (λ_i \norm{\vy_i}_2 + \vec{ν}_i^T \vy_i) + \sum_{i=1}^m (-λ_i + μ_i) t_i - \sum_{i = 1}^n (\vb_i \vec{ν}_i + d_i μ_i)
\end{align*} which is bounded below over $x$ if and only if $\sum (\mA_i^T \vec{ν}_i + μ_i \vec{μ}_i \vc_i) = \vc$. To minimize over $y_i$, we note that $\inf_{y_i} λ_i \norm{y_i}_2 + ν_i^T \vy_i$ is 0 only if $\norm{ν_i}_2 ≤ λ_i$ and 0 otherwise. The minimimum over $t_i$ is bounded below if and only if $λ_i = μ_i$ so the Lagrangian is \[ g(λ,ν,μ) = \begin{cases}
- \sum_{i = 1}^n (b_i^T ν_i + d_i μ_i) & \text{all previous conditions for lower bounds hold} \\
- ∞ & \text{otherwise}
\end{cases}\]

To try and transform a problem of minimizing $f(x)$ s.t. $\norm{x}_∞ < 1$ to SOCP we can write it as the minimization of $t$ subject to $f(x) ≤ t$ and then get things.


\subsection{Semi-Definite programming}

We have to minimize $\vc^T \vx$ subject to $G + \sum x_i F_i ≤ 0$. The inequality constraint is called LInear Matrix Inequality. The traditional LP problem is the same but constraints $\mop{diag}(\mA \vx - \b) ≤ 0$.

Eigenvalue minimization is equivalent to minimizing $t$ such that $\mA(\vx) ≤ t \mI$ with $\mA = \mA_0 + \vx_1 \mA_1 + \dotsb + \vx_n \mA_n$ with symmetric matrices.

We can also minimize matrix norm, minimizing $t$ such that \[ \begin{pmatrix} t \mI & \mA(\vx) \\ \mA(\vx)^T  & t \mI \end{pmatrix} ≥ 0\]

We can also move the IPM so that the method is \[ t \vc_i - \tr (F_iF(\vx^*(t))^{-1}) = 0\] with dual point $Z^*(t) = - \frac{1}{t} F(\vx^*(t))^{-1}$ is feasible for the problem of maximization $\tr(GZ)$ subject to $\tr(F_iZ) + \vc_i = 0$ and $Z ≥ 0$.

\subsection{CVX}

In MATLAB.

\begin{minipage}{0.5\textwidth}
\begin{verbatim}
cvx_begin
	variable x(n);
	minimize(norm(A*x - b));
	subject to
	C*x == d ;
	norm(x, Inf) <= 1;
cvx_end
\end{verbatim}
\hrulefill
\begin{verbatim}
cvx_begin
	variable x(n);
	dual variable y;
	minimize (c' * x);
	subject to
		y : A^* <= b;
cvx_end
\end{verbatim}
\end{minipage}
~
\begin{minipage}{0.5\textwidth}
\begin{verbatim}
D = [.15 107 45 70; .25 500 40 121; 0.05 0 60 65];
cvx_begin
	variable x(3)
	cost = D(:,1)'*x;
	vitamin = D(:,2)'*x;
	sugar = D(:,3)'*x;
	calories = D(:,4)'*x;
	minimize
	( cost )
	subject to
	calories <= 2250; calories >= 2000;
	vitamin >= 5000; vitamin <= 10000;
	sugar <= 1000;
	x >= 0;
	x <= 10;
cvx_end
\end{verbatim}
\end{minipage}

Dual variable relate to the lagrangian, the $:$ signal the constraint to which they are attached.,

\section{Vector optimization}

We can optimize vectorial functions $\appl{f}{ℝ^m}{ℝ^n}$ assuming we restrict the values we look at to a cone $K ⊆ ℝ^n$. It will be called a proper cone if it is convex, closed, nonempty interarior and pointed (that is, $x ∈ K \y -x ∈ K \implies x = 0$). There, we can define the inequalities
\begin{align*}
x \preceq_K y &\iff x - y ∈ K \\
x \prec_K y &\iff x - y ∈ \mop{int}\, K
\end{align*}

For example, if we set $K = ℝ^n_+$ then $x \preceq y$ is $x_i ≤ y_i$ for all components. Properties of usual ``less than'' hold, for example summing inequations. Not a linear order however.

Differentiate between minimum ($x \preceq y\, ∀ y ∈ S ⊆ K$) and minimal ($∀y ∈ S, y \preceq x \implies y = x$).

We can define the dual cone $K^* = \set{ y ∈ ℝ^n \st \pesc{y,x} ≥ 0 \; ∀x ∈ K}$. $ℝ^n_+$, $S_+^n$ are self-dual. Dual cones are also proper, with inequalities $y \succeq_{K^*} 0 \iff \pesc{y,x} ≥ 0 \,∀x\succeq_K 0$. This gives rise to definitions of minimum element $x ∈ S$ w.r.t. $\preceq_K$ iff for all $λ \prec_{K^*} 0$ $x$ minimizes $\pesc{λ,z}$ over $S$. It is minimal it it is only for some $λ$.

With a set of achievable objective vales $\mathcal{O}$ we have that $x$ is optimal if $f_0(x)$ is the minimum value and Pareto optimal if it is minimal. If we are optimizing a function $\appl{f_0}{ℝ^m}{ℝ^n}$, we have an optimal $x^*$ if for any other $y$ feasible we have $f_0(x^*) \preceq f_0(y)$. In this case, objectives are noncompeting.

A feasible $x^p$ is Pareto optimal if we have other optimal values.

To solve this, we choose a $λ \succ_{K^*} > 0$ and solve the scalar problem of minimization $\pesc{λ, f_0(x)}$. If the problem has an optimal, then it is Pareto optimal. For convex optimization problems we can find almost all Pareto optimal points by varying $λ$.

\section{Perturbation and sensittivity analysis}

\subsection{Perturbations}

Given a problem of minimizing $f_0(x)$ subject to $f_i(x) ≤ 0$ for $i = 1, \dotsc, m$ and $h_i(x) = 0$ for $i = 1, \dotsc, p$ (and the corresponding dual of maximimization $g(λ,ν)$ subject to $λ ≥ 0$) we can consider the perturbed problem with the same subject subject to restrictions $f_i(x) ≤ u_i$, $h_i(x) = v_i$ and the dual $g(λ,ν) - \pesc{u,λ} - \pesc{v, ν}$ with $u,v$ parameters. We are interested in information about the optimal $p^*(u,v)$.

Applying weak duality we have that $p^*(u,v) ≥ g(λ^*, v^*) - u^{T} λ^* - v^Tν^*$ with $g(λ^*, v^*) = p^*(0,0)$. From there we can get things.

If $p^*$ is differentiable, then $λ_i^* = - ∂_{u_i} p^*$ and $ν_i^* = - ∂_{v_i} p^*$ at $(0,0)$.

\subsection{Robustness}

E.g., minimize $\norm{\mA x - b}$ with uncertain $\mA$. we can try to minimize the expectance or minimize the worst case (which is tractable only in certain cases).

We might also want to perform linear discrimination, separating two sets of points $X = \set{x_1, \dotsc, x_n}$, $Y = \set{y_1, \dotsc, y_n}$ by an hyperplane so that
\[ \begin{cases} \va^T \vx + b > 0 & \vx ∈ X \\
\va^T \vy + b < 0 & \vy ∈ Y
\end{cases}
\]

This is homogeneous in $\va, b$ so that it is equivalent with $≥ 1$ instead of $> 0$ and viceversa. The advantage is that then the distance between hyperplanes $\va^T \vz + b = \pm 1$ is $\frac{1}{\norm{a}_2}$. Then, to separate two sets of points by maximum margin we have to minimize $\frac{\norm{a}_2}{2}$  subject to $\va \vx + b ≥ 1$, $\va \vy + b ≤ -1$ which after squaring the objective is a quadratic problme in $\va, b$.

The Lagrange dual is maximizing $\vec{1}^T \vec{λ} + \vec{1}^T \vec{μ}$ subject to $2\norm{\sum_{i=1}^n λ_i \vx_i - \sum_{i = 1}^n μ_i \vy_i}_2 ≤ 1$, with $\vec{1}^T \vec{λ} = \vec{1}^T \vec{μ}$ and $\vec{μ}, \vec{λ} \succeq 0$. Then the optimal value is the inverse of the distance between convex hulls. To compute this, we need to get the lagrangian and then find conditions to have minimum $> ∞$.

This can be converted to the same problem but with linear constraints $\va^T \vx_i + b ≥ 1 - u_i$ and $\va^T \vy_i + b ≤ - 1 + v_i$. At optimum, $λ_i = \max \set{0, 1 - \va^T x_i - b}$ and $v_i = \max{0, 1 + \va^T\vy + b} $.

The Support vector classifier has the same constraints but miminizes $\norm{a}_2 + γ(\vec{1}^T \vu + \vec{1}^T \vv)$ which produces a tradeoff curve between inverse of margin and classification error which is given by the total slack.

\section{Hypothesis testing}

Choose whether $X ∈ \set{1, \dotsc, n}$ was generated by distribution $p = (p_1, \dotsc, p_n)$ or $q = (q_1, \dotsc, q_n)$. Observing $X = k$ leads to choosing H1 with probability $t_{1,k}$ and H2 with probability $t_{2,k}$. We can then build the detection probability matrix \[ \mD = \begin{pmatrix} 1 - P_{fp} & P_{fn} \\ P_{fp} & 1 - P_{fn} \end{pmatrix} \qquad \begin{cases} P_{fp} ≝ 1 - \sum_{k = 1}^n t_{1,k} p_k \\ P_{fn} ≝ \sum_{k = 1}^n t_{1,k} q_k \end{cases} \] with $P_{fp}$ the probability of selecting H2 if $X$ generated by distr. 1 (false pos) and $P_{fn}$ the probability of selecting H1 if $X$ is generated by distr. 2 (false negavtive). To design this detector we will want to minimize $(P_{fp}, P_{fn})$ w.r.t. $ℝ^2_+$ subject to $t_{1,k} + t_{2,k} = 1$ and $t_{i,k} ≥ 0$.

It is obvious that best option is to choose the value with higher probability. If both probs are equal we have several Pareto-optimal detectors.

\section{Random factoids}

The solution of the least squares minimization $\norm{\mA \vx - \vb}^2 $ is $\vx = (\mA^T \mA)^{-1} \mA^T \vb$. It can also be solved with the pseudo inverse $\vx = \mA^\dagger \vb$, with $\mA = \mU Σ \mV^T$ the singular value decomposition and the pseudoinverse $\mA^{\dagger} = \mV Σ^{-1} \mU^T$.

In MATLAB, \texttt{linprog(f, A, b)} solves linear programming $\vf \vx$ subject to $\mA \vx ≤ \vb$. \texttt{quadprog(H, f, A, b)} solves quadratic programming $\frac{1}{2} \vx \mH \vx + \vf \vx$ subject to $\mA \vx ≤ \vb$.

One can also solve minimization problems with the Lagrangian. For example, we can minize $\vx^T \mQ \vx$ such that $\mA \vx = \vb$. The lagrangian is \[ \mathcal{L}(\vx, \vec{ν}) = \vx^T \mQ \vx + \vec{ν}^T(\mA\vx - \vb) \] with gradient $∇\mathcal{L} = 2 \mQ \vx + \mA^T \vec{ν}$. Setting that gradient to $0$ gives $\vx = - \frac{1}{2} \inv{\mQ} \mA^T \vec{ν}$. Now we switch to the dual function $g ≝ \inf_{\vx ∈ D} \mathcal{L}$ with derivative $g' = \mA \vx - \vb = - \frac{1}{2} \mA \inv{\mQ} \mA^T \vec{ν} - \vb = 0$. There we get the value for $\vec{ν}$ and $\vx = - \inv{\mQ} \mA^T (\mA \mQ^{-1} \mQ^T)^{-1} \vb$.

If we want to minimize $\norm{\mA\vx - \vb}_1$ over $\norm{x}_∞ ≤ 1$ the LP is minimization of $\sum y_i$ s.t. $- \vy \preceq \mA \vx - \vb \preceq \vy$ and $- \vec{1} \preceq \vx \preceq \vec{1}$.

Portfolio problems are described by a position vector $\vx ℝ^n$, a vector of returns $\vr ∈ ℝ^n$ and the level of risk (variance) defined by $\vec{x}^T \mC \vx$ with $\mC$ the covariance matrix.

To show that a value is optimal, it needs to be feasible and we need to find a value for the dual variable that satisfies KKT and is dual feasible.

\subsection{Schur's complement}

Given block matrices $\mA,\mB, \mC, \mD$ of dimensions $p×p$, $p×q$, $q×p$ and $q×q$ with $\mD$ invertible, we can define the block matrix \[ \mM = \begin{pmatrix} \mA & \mB \\ \mC & \mD \end{pmatrix} \] and the following Schur complements of $\mA$ and $\mD$:
\begin{align*}
\quot{\mM}{\mD} &≝ \mA - \mB \inv{\mD} \mC \\
\quot{\mM}{\mA} &≝ \mD - \mC \inv{\mA} \mB
\end{align*}

This is useful to solve a system of linear equations \[ \begin{cases} \mA \vx + \mB \vy = \va \\ \mC \vx + \mD \vy = \vb \end{cases}\] then we can solve $\quot{\mM}{\mD} \vx = \va - \mB \inv{\mD} \vb$ and then we can replace in the second equation which reduces the number of matrices to invert.

Also, if $\mX = \begin{pmatrix} \mA & \mB \\ \mB^T & \mC \end{pmatrix}$ then $\mX$ is positive definite iff both $\mA$ amd $\quot{\mX}{\mA}$ are both pd, and same with $\mC$.

\end{document}
