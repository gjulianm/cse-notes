\documentclass[palatino]{epflnotes}

\title{Computer simulation of physical systems}
\author{Guillermo Julián Moreno}
\date{16/17 - Fall semester}

% Additional packages
\usepackage{tikztools}
% --------------------

\begin{document}
\frontmatter
\pagestyle{plain}
\maketitle

\tableofcontents
\mainmatter
% Content

\chapter{Preliminaries}

\textit{Trigger warning: Mathematics explained by a physics professor.}

\section{Differential equations}

We are interested in a general differential equation of the form \[ \od{y}{x} = f(x,y) \], that is, first order equations. We are not interested in second order problems, although we can always downgrade. For example, given a momentum equation such as \[ m \od[2]{z}{t} = F(z) \], we can simplify to two first-order equation such as \[ \od{z}{t} = \frac{p(t)}{m} \qquad \od{p}{t} = F(z) \]

All this boils down that we're are going to have initial value problems for $\vy(0) = y_0$, and then we will want to get how does $\vy$ evolve with time.

In order to solve these kinds of equations numerically, we will have several points? steps?. The first one is \textbf{discretization}, introducing evaluations at a finite number of points with step $h$\footnote{That is, points given as $x_n = x_0 + n·h$.}. The issue is the size of the step, which depends on the application being done.

The second point is a \textbf{recursion formula}: that is, how to get the $n$-th value $y_n$ as a function of the previous values $y_{n-1}, y_{n-2}, \dotsc$.

The simplest formula is called the Euler method.

\begin{prop}[Euler method] \label{prop:EulerMethod} Let $y(x)$ be a ¿? function with the differential equation $\iod{y}{x} = f(x,y)$ with $f$ being another ¿? function. Let $y(x_n) = y_n$ be a value of the equation. Then we can obtain the next value by the given formula: \( y_{n+1} = y_n + h · f(x_n, y_n) + \mathcal{O}(h^2) \)
\end{prop}

However, this is a simple method and not very accurate, as it has a low convergence rate. Another method is based on Taylor expansion of again functions in some absolute random space.

\begin{prop}[Taylor expansion method] In the same conditions (that is, no conditions) of \fref{prop:EulerMethod}, we can use a method of higher-order accuracy: \( y_{n+1} = y_n + hf(x_n, y_n) + \frac{1}{2}h^2 \left(\dpd{f}{x}(x_n, y_n) + f (x_n, y_n) \dpd{f}{y}(x_n, y_n\right) + \mathcal{O}(h^3) \label{eq:TaylorExpansion} \)
\end{prop}

We can, however, achieve the same accuracy with a three-point method.

\begin{prop}[Symmetric differences method] In the same no conditions previously not explained, we can approximate by \( y_{n+1} = y_{n-1} + 2hf(x_n, y_n) + \mathcal{O}(h^3)\)
\end{prop}

The disadvantage is that here we need to be able to differentiate $f$ with respect to $x$ and $y$, something that will not always be easy.

Runge-Kutta. Advantages: accuracy 2nd order,  no easy differentiability required (unlike Taylor), can start right away (unlike multistep), no linearity $f$ in $y$ (implicit linearity)
 and can change step size.

\subsection{Stability}

\begin{figure}[hbtp]
\inputtikz{ExponentialApprox}
\caption{A numerical approximation of the ODE $y' = -y$ can suffer from stability problems when the solution goes to 0.}
\label{fig:ExponentialApproxProblem}
\end{figure}

One interesting aspect to study is the stability of the methods. For example, let's consider the problem \begin{align*} y' &= -y \\ y(0) &= 1 \end{align*}

This problem has an exact solution given by $y = e^{-x}$.

\chapter{Molecular dynamics}

\section{Classical molecular dynamics}

One of the main purposes when doing simulations of molecular dynamics is to find equilibrum properties of some quantity that depends on the position of the particles and their momemtum. We might also want to calculate time correlation functions, seeing how does a particle evolve in time.

The first step if the definition of the variables and their interactions, which is done by the definition of the hamiltonian. It is also necessary to define the initial configuration. There will finally issues with boundary conditions: we don't want to see physical effects at boundaries so there are several possibilities.

We will be also interested in the cutoff radius $r_C$, the limit until which we suppose forces can act.

However, we will find various issues: the quality of the interactions, the size of the system, the time, accuracy and statistical noise limit the size of the system we can simulate.

Depending on what we want, we can use several methods. If we want to take ensemble averages, we don't care about the exactness of trajectories. However, we will care about that if the want to get correlation functions.

Considerations for algorithms:

\begin{enumerate}
	\item One force evaluation per time step.
	\item Accuracy $o(Δt^4)$: we want to take into account the velocity, the force and the change in acceleration to account for changes in stability.
\end{enumerate}

\subsection{Verlet-Störmer algorithm}

If we start from \[ r(t + Δt) = r(t) + v(t) Δt + \frac{f(t)}{2m}Δt^2 + \frac{Δt^3}{3!}R''' + o(Δt^4) \] we can add $r(t+Δt) + r(t-Δt)$ and then we have the equation \[ r(t + Δt) = 2r(t) - r(t - Δt) + \frac{f(t)}{m}Δt^2 + o(Δt^4) \] which is the position-Verlet and only requires one evaluation of the force. This does not require any evaluation of the velocity.

However, in order to be able to verify the conservation of energy in a system we need the velocity (kinetic energy) which is easily calculated as \[ v(t) = \frac{r(t + Δt) - r(t-Δt)}{2Δt} + o(Δt^2) \]

In order to have more accurate velocity, we have to have Newton equation $m\ddot{r} = f$ which deriving again is $\dddot{r} = \dot{f}{m}$ which can be approximated by $\frac{f(t+Δt) - f(t-Δt)}{2Δtm} + o(Δt^2)$ and the final formula looks like \[ v(t) = \frac{r(t + Δt) - r(t-Δt)}{2Δt} + \frac{Δt}{12}\left[f(t+Δt)-f(t - Δt)\right] + o(Δt^6)\] which however is not especially good neither.

The disadvantage of this algorithm is the factor $2r(t) - r(t - Δt)$, which is a problem if these two quantities and large but their difference is small, as the accuracy of floating point numbers can fail here.

\subsection{Leap-frog Verlet}

To fix the previous issues, we introduce a half-step: \begin{align*}
r(t + Δt) &= r(t) + Δt · v(t + \sfrac{Δt}{2}) \\
v(t + Δt) &= v(t - \sfrac{Δt}{2}) + Δt· \frac{f(t)}{m}
\end{align*}

This algorithm is equivalent to the previous one, I'm not going to copy the steps.

The advantage is that there is no loss of accuracy due to differences between large numbers, but we don't know velocities and posiitons at the same moment.

\subsection{Velocity Verlet}

The most convenient algorithm for the classical method without the problem of the previous two is \begin{align*}
r(t + Δt) &= r(t) + Δt v(t) + \frac{Δt^2 F(t)}{2m} \\
v(t + Δt) &= v(t) + \frac{Δt}{2m}\left[F(t) + F(t + Δt)\right]
\end{align*}

Again, this is equivalent to the previous ones.

The nice thing about this algorithm is that it gives conservation of energy (supposing one doesn't make roundoff errors).

\subsubsection{Stability of Verlet algorithms}

We are going to IDK with an harmonic oscillator: \[ \ddot{x}(t) = -ω_0^2 x(t)\] which has the solution $x(t) = e^{\imath ω t}$ with $ω$ related to the discretization $h$ as \[ 2 - 2\cos ω h = h^2 ω_0^2\]

Here we can see that $h^2 ω_0^2 > 4$, we don't have any real solution for $ω$ and thus the solution diverges immediately (exponential order).

On the other hand, if $ωh \ll 1$ we can do computations and see that $ω ≠ ω_0$ if $h ≠ 0$, so we see something that is not exactly the real solution.

\subsection{Gear algorithm}

Given a force $\ddot{x}(t) = f(x)$, we define the vector \[ \vy_n = \begin{pmatrix} x_n & Δt \dot{x}_n & \frac{Δt^2}{2} \ddot{x}_n & \frac{1}{6} Δt^3 \dddot{x}_n \end{pmatrix}^T \]

The first step is a predictor based on Euler/Taylor, so we can predict the next position based on \[ \vy_{n+1}^P = \underbracket{\begin{pmatrix} 1 & 1 & 1 & 1 \\ 0 & 1 & 2 & 3 \\ 0 & 0 & 1 & 3 \\ 0 & 0 & 0 & 1 \end{pmatrix}}_A \vy_n \]

Then we calculate the force $f(x_{n+1}^P)$ (the position is the first component of $\vy^P$), and then the final step is the correction \[ \vy_{n+1} = \vy_{n+1}^p + \va \frac{Δt^2}{2} \left[f(x_{n+1}^P) - \ddot{x}_{n+1}^P \right] \] with $\va = \begin{pmatrix} \sfrac{1}{6} &\sfrac{5}{6} & 1 & \sfrac{1}{3}\end{pmatrix}^T$.

The criteria for fixing the values are accuracy, stability and of course the fact that the force doesn't depend on time.

Again, we can test the precision of this algorithm on a harmonic oscillator.  We want to see the maximum error, the noise in the total energy and the drift (how much energy are we losing).

Magical transparency, Gear is best at small steps, become comparable to Verlet at higher values.

\section{Simulation as a computer experiment - Rahman's simulation}

Box something, periodic boundary conditions. NVE (constant temperature) and the lennard-Jones potential \[ U = \sum_{i < j} u_{ij} = \sum_{i < j} u^{ij}\norm{r_i - r_j} \] with \[ u^{ij}(r) = 4ε \left(\frac{σ^2}{r^{12}} - \frac{σ^6}{r^6} \right)\]

Computations of atomic forces. Instantaneous temperature: equipartition theorem. Radial distribution function.

\subsection{Diffusion coefficient in molecular dynamics}

But we can also study things that are not static. For example, we might want to study the \textbf{diffusion coefficient}, which is related to Fick's law explaining macroscopic behaviour of liquids: \( \vec{J} = -D \grad c \) where $\vec{J}$ is the current in the material, $c$ is the concentration and $D$ is the diffusion coefficient.

We also have the continuity relation, which assures us that the material does not disappear: \( \dpd{c}{t}(\vr, t) + \dv \vec{J} (\vr, t) = 0\)

Combining these equations gets us the diffusion equation: \( \dpd{}{t} c(\vr, t) - D Δc(\vr,t) = 0 \) which for initial conditions\footnote{HAASIODJAHSDA DELTA IS NOT A FUNCTION!} $c(\vr, 0) = δ_{\vr_0}$ has solution \[ c(\vr, 0) = \frac{1}{\left(4πDt\right)^{\sfrac{3}{2}}} e^{-\frac{\norm{\vr}^2}{4Dt}} \]

We might want to study the average of the squared norm of $\vr$: \[ \int_{ℝ^N} c(\vr, t) \norm{\vr}^2 \dif \vr = \dotsb = 6 Dt\] which gives us a way of obtaining the diffusion coefficient experimentally.

What happens, however, if the initial condition is not a delta \textit{distribution}? Well, the solution is the convolution of the initial conditions $f(\vr) ∈ L^1(ℝ^N)$ with $\norm{f}_1 = 1$  with the essential solution (Gaussian) given by \[ \Phi(\vr,t)=\frac{1}{\sqrt{4\pi Dt}}\exp\left(-\frac{\vr^2}{4Dt}\right) \] so our equation becomes \begin{align*}
\int_{ℝ^N} c(\vr, t) \norm{\vr}^2 \dif \vr &= \int_{ℝ^N} (f \ast Φ) \norm{\vr}^2 \dif \vr = \\
	&= \int_{ℝ^N} \left(\int_{ℝ^N} f(\vx) Φ(\vr - \vx, t) \dif \vx \right) \norm{\vr}^2 \dif \vr = \\
	&= \int_{ℝ^N} f(\vx) \left(\int_{ℝ^N} Φ(\vr - \vx, t) \norm{\vr}^2 \vr \right) \dif \vx = \\
	&= 6Dt · \int_{ℝ^N} f(\vx) \dif x = 6Dt
\end{align*} which agains tells us that the evolution of the second moment is proportional to $t$ and the diffusion coefficient.

In a simulation, we would calculate the diffusion coefficient as \[ D = \lim_{t \to ∞} \frac{1}{6t} \pesc{\norm{Δ\vr(t)}^2} \] with \[ \pesc{\norm{Δ\vr(t)}^2} = \frac{1}{N} \sum_{i=1}^N \norm{\vr_i(t) - \vr_i(t_0)}^2\] for $t_0$ the initial time of the simulation.

A simulation of Rahman's experiment reveals that in short time scales (picoseconds) Fick's law already applies at the atomic level.

\subsubsection{Green-Kubo relation for the diffusion coefficient}

Another way to obtain the diffusion coefficient is something that I did not listen to but the formulas are \[ Δ\vr_x(t) = \int_0^t \dif t' \vv_x(t') \] and \begin{align*}
\pesc{\abs{Δ\vr_x(t)}^2} &= \pesc{\left(\int_0^t \dif t' \vv_x(t')\right)^2 } = \\
&= \dotsb =  \\
&= 2 \pesc{\int_0^t \dif t' \int_0^{t'} \dif t'' \vec{v}_x(t') \vv_x(t'') }
\end{align*}

And now \[ D = \lim_{t\to ∞} \frac{1}{2} \dpd{}{t} \pesc{\abs{Δ\vr_x}^2}\] beacuse the material is isotropic or something like that and at equilibrum and after some horrible calculations we have that \[ D = \int_0^{∞} \pesc{\vv_x(τ) \vv_x(0)} \dif τ \]

\section{Constant temperature simulations - Sampling in the canonical ensemble}

Although in a setting with an infinite number of particles temperature can remain constant, in the canonical ensemble (CE) there are specific fluctuations related to the fact that there is only a finite number of particles. So $T_i \propto \sum_{I} p_I^2$ and then \begin{multline*} \frac{\pesc{(ΔT)^2}}{T^2} = \frac{\pesc{(T_i - \pesc{T_i})^2}}{\pesc{T_i}^2} = \frac{\pesc{\left(\sum_I p_I^2\right)^2} - \left(N\pesc{p}\right)^2}{\left(N\pesc{p}\right)^2} = \frac{\pesc{\sum_{I,J}p_I^2p_J^2} - \left(N\pesc{p}\right)^2}{\left(N\pesc{p}\right)^2} = \\ = \frac{N\pesc{p^4} + N(N-1)\pesc{p^2}\pesc{p^2} - \left(N\pesc{p}\right)^2}{\left(N\pesc{p}\right)^2} = \frac{1}{N} \frac{\pesc{p^4} - \pesc{p^2}^2}{\pesc{p^2}^2} = \frac{2}{3N}\end{multline*}

We have used here the distribution of momentum Maxwell-Boltzmann given by \[ \mathcal{P}(p) = \left(\frac{β}{2πm}\right)^{\sfrac{3}{2}} e^{-\frac{βp^2}{2m}} \] with $β = \frac{1}{kT}$, so the moments can be calculated \begin{align*}
\pesc{p^2} &= \frac{3m}{β} \\
\pesc{p^4} &= 15 \frac{m^2}{β^2}
\end{align*}

In the microcanonic ensemble, Lebowitz et al. found that the fluctuations are \[ \frac{\pesc{(ΔT)^2}}{T^2} = \frac{2}{3N} \left(1 - \frac{3k}{c_v} \right)\]

\chapter{Monte Carlo simulations}

\appendix

\chapter{Evaluation methods}

There are two ways to get to the exam.

\paragraph{Choose a simulation project (Recommended)} Choose a project from the web (password \textit{simphys}). Follow two hours per week of the course for a general background. We get to the exam by handing in at the end of the semester (21\textsuperscript{st} December). Ten minutes of presentation of the project at the exam plus questions. Deadline for project approval is in two weeks (aka first week of October).

The project must be done with a person of the Faculty of Basic Sciences, in C/Fortran. It should be original research. The description must be one A4 page with the proposant (professor proposing, with name and address), the motivation behind the project, the methods envisioned/considered for the project, and the student's email and name. This has to be submitted through the webpage.

Two hard copies of the report, handed in in the professor's office or in the letterbox. It also has to be uploaded to Moodle, along with the code.

The report must have the following structure:

\begin{enumerate}
\item Introduction \& motivation. Why is the simulation is necessary and ffs it's like every other introduction.
\item Description of the model.
\item Implementation of the computer code.
\item Benchmarks.
\item Results + discussions.
\item Conclusions.
\end{enumerate}

The evaluation criteria is the following:

\begin{enumerate}
\item Choice of topic and level of challenge.
\item Achieved results: quality of the computational work and physical understanding of the problem.
\item Quality of the reports.
\item Quality of the oral presentation.
\item Answers to the questions (depth of understanding).
\item Expert present at the exam gives a feeling of the work.
\end{enumerate}

\paragraph{Exercise sessions} They give code, we do magic with the code. Then we have a report and then an exam with questions on the course.

%\chapter{---}
%\input{tex/ComputerSimulationOfPhysicalSystemsI_Exerc.tex}

\backmatter
\printindex
\end{document}
