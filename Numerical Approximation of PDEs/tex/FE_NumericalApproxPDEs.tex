% -*- root: ../NumericalApproximationofPDEs.tex -*-
\chapter{Elliptic problems}

\section{Poisson problem}

We start by considering a simple Poisson equation, given $Ω ⊂ ℝ^d$ a bounded open domain with Lipschitz boundary $∂Ω$. There, we set the problem \[ \begin{cases}
-Δu = f & \text{ in } Ω \\
u =  0 & \text{ in } ∂Ω
\end{cases} \]

In \fref{sec:Theory:WeakFormulationPDE} we saw that the weak abstract form was  \[ \int_Ω \grad u · \grad v = \int_Ω f v \]

It is easy to see that we can apply the \nref{thm:Theory:LaxMilgram} to our problem: if $v ∈ H^1_0(Ω)$, then its $L^2$-norm is bounded so \[ \abs{\int_Ω fv} ≤ \norm{f}_{L^2} \norm{v}_{L^2} ≤ \norm{f}_{L^2} \norm{v}_{H^1} < ∞ \]

Same happens with $a$: the boundedness is directly obtained from the fact that $u, v ∈ H^1_0(Ω)$. Coercivity can be a little bit more complicated. For that, we must use the \nref{thm:PoincareInequality} which tells us that there is a constant $C_p > 0$ such that $\int v^2 ≤ C_p \int \abs{\grad u}^2$ for all $u ∈ H_0^1$. So, in this case we have that \[
\norm{u}^2_{H^1} = \int v^2 + \int \abs{\grad v}^2 ≤ (1+C_p^2) \int \abs{\grad u}^2
\] so our coercivity constant is $\frac{1}{1 + C_p^2}$.

This means that, applying the \nref{thm:Theory:LaxMilgram}, we have a unique solution $u ∈ V$ such that \[ \norm{u}_{H^1_0} ≤ (1+C_p^2) \norm{F}_{H^1_0} \]

\subsection{Poisson problems with mixed boundary conditions}

We will want to know what happens when we have mixed boundary conditions, that is, \nref{def:Theory:DirichletBoundary} and \nref{def:Theory:NeumannBoundary}. We will study the problem \( \begin{cases}
-Δu =f & \text{in }Ω \\
u = g & \text{on }Γ_D \\
∂_\vn u = h & \text{on }Γ_N \end{cases} \) with $Γ_D ∪ Γ_N = ∂Ω$.

We can start with the weak formulation as previously \[ \int_Ω fv = \int_Ω -Δu v = \int_Ω \grad u · \grad v - \int_{∂Ω} ∂_\vn u v = \int_Ω \grad u \grad v - \int_{Γ_N} ∂_\vn v - \int_{Γ_D} ∂_n u v\]

The problem here is how to deal with the boundary term on $Γ_D$. As we did in the previous section, we can select $\restr{v}{Γ_D} = 0$. Thus, our weak formulation is \( \int_Ω \grad u · \grad v = \int_Ω f v + \int_{Γ_N} h v \label{eq:Elliptic:WeakFormulationMixedBoundary} \) with $v ∈ H^1_{Γ_D}$, where we can define \( H^1_{Γ_D} = \set{ v ∈ H^1 \tq \restr{v}{Γ_D} = 0 } \)

Our solution should however live in $V_g = \set{v ∈ H^1 \tq \restr{v}{Γ_D} = g}$, which is not linear but only an affine subspace.

If we have $g = 0$, we still can use a \nlref{def:Theory:WeakAbstractFormulation} with $F(v) = \int fv + \int_{Γ_N} hv$ to find a solution $u ∈ H^1_{Γ_D} = V_0$. With $g ≠ 0$ things become a little bit more difficult.

\subsubsection{Lifting technique}

If the datum $g$ is not null, we need to find a solution $u ∈ V_g$, and as we said before this is not a linear subspace and, even worse, it is different to the test space $V_0$ so we cannot apply Lax-Milgram.


However, if $g ∈ H^{\sfrac{1}{2}}(∂Ω)$, we can apply the \nref{thm:Fund:Trace} and show that it is the trace of some function $G ∈ H^1(Ω)$ such that $\restr{G}{∂Ω} = g$ and $\norm{G}_{H^1(Ω)} ≤ γ\norm{γ}_{H^{\frac{1}{2}}(∂Ω)}$. We can then write $u = u_0 + G$ with $u_0 ∈ V_0$, and as $a$ is a linear form the weak abstract form changes: \begin{align*}
a(u, v) &= F(v) \\
a(u_0 + G, v) &= F(v) \\
a(u_0, v) &= \underbracket{F(v) - a(G, v)}_{\tilde{F}(v)}
\end{align*} which is a problem for which we can apply the \nref{thm:Theory:LaxMilgram} and solve for $u_0$, and then reconstruct the solution as $u = u_0 + G$.

\subsection{Derivation of the weak formulation based on calculus of variations}

We can try to study other approach to this problem with an example, which is the deformation $u$ of a membrane $Ω$ under a certain force $f$. In that case, we try to find a solution that minimizes the elastic energy $E = \int_Ω \frac{1}{2} κ \norm{\grad u}^2$. Supposing $κ = 1$, our energy functional to minimize is \( J(u) = \frac{1}{2} \int_Ω \norm{\grad u}^2 - \int_Ω f u - \int_{Γ_N} h u \label{eq:Elliptic:EnergyFunctional} \) so our solution should be \[ u = \argmin_{\substack{v ∈ H^1(Ω) \\ v = \restr{g}{Γ_D}}}  J(v) \] where we search for the function in $H^1(Ω)$ because we need for the gradient to be square integrable. We need also $f ∈ L^2$, and $h ∈ H^{-\sfrac{1}{2}}$ (the topological dual space of $H^{\sfrac{1}{2}}$) to be able to integrate that last term.

So, how do we do this? If the argument was real, we could find the point with gradient $0$ (all directional derivatives are null). But the functional $J$ from \eqref{eq:Elliptic:EnergyFunctional} is an application $\appl{J}{H^1}{ℝ}$, so we need something different. However, we can still translate the concept of ``gradient $0$''. If $J$ were a real variable function, we could do \[ \grad J (u) = 0 \iff \grad J(u) · \vA = 0\; ∀\vA ∈ ℝ^N \iff \lim_{ε \to 0} \frac{J(u + ε\vA) - J(u)}{ε} = 0 \]

That last notion is the one we can translate to the functional case. If we consider $u$ to be the equilibrum, we can study any variation of $u ∈ V_g$\footnote{Remember from the previous section that $V_g = \set{v ∈ H^1 \tq \restr{v}{Γ_D} = g}$.} such that $u + ε v ∈ V_g$ (that is, respecting the boundary conditions), with $v ∈ V_g$ forcibly.

Knowing this, we can try to calculate the ``derivative'', where some linear terms will be canceled but we will have to deal with the quadratic ones:
\begin{align*}
\Dif_v J(u) &= \lim_{ε \to 0} \frac{J(u + εv) - J(u)}{ε} = \\
	&= \lim_{ε \to 0} \frac{1}{ε} \left[ \frac{1}{2} \int_Ω \grad(u+εv)· \grad(u + εv) - \int_Ωf(u + εv) - \int_{Γ_N} h · (u + εv)\right. \\
	&\qquad \left.- \frac{1}{2}\int_Ω \grad u \grad u + \int_Ω fu + \int_{Γ_N} h u \right] = \\
	&= \lim_{ε \to 0}\frac{1}{ε} \left[ \frac{1}{2}\left( \int_Ω \grad(u+εv) \grad (u + εv) - \grad u \grad u \right) - ε \int_Ω fv - ε \int_{Γ_N} h v \right] = \\
	&= \lim_{ε \to 0}\frac{1}{ε} \left[ \frac{1}{2} \left( \grad u \grad u + ε \grad u \grad v + ε \grad v \grad u + ε^2 \grad v \grad u - \grad u \grad u\right) - ε \int_Ω fv - ε \int_{Γ_N} h v \right] = \\
	&= \int_Ω \grad u \grad v - \int_Ω fv - \int_{Γ_N} h v
\end{align*} which is the same weak formulation of the problem we had previously in \eqref{eq:Elliptic:WeakFormulationMixedBoundary}.

\subsection{Regularity of the solution}

We may have proved that the solution exists, but we will also be interested in knowing the regularity of the function in order to be able to prove rates of convergence, for example. That will be given in the following theorem.

\begin{theorem}[Shift theorem][Theorem!shift] \label{thm:PDE:Shift} Consider the PDE problem \[
-Δu =f \qquad \text{in }Ω \] with $f ∈ H^m(Ω)$, $Ω$ a smooth domain ($∂Ω ∈ C^{m+2}$, that is, we can parametrize the boundary as a $C^{m+2}$ manifold) and with the following restrictions depending on the boundary conditions:
\begin{itemize}
	\item Full Dirichlet conditions $\restr{u}{Γ_D} = g ∈ H^{m + \sfrac{3}{2}}(Ω)$.
	\item Full Neumann conditions $∂_\vn u = h ∈ H^{m + \sfrac{1}{2}}(Ω)$.
\end{itemize}

Under those conditions, $u ∈ H^{m+2}(Ω)$.
\end{theorem}

\subsubsection{Corner singularities}

\begin{wrapfigure}{L}{0.3\textwidth}
\centering
\inputtikz{CornerSingularity}
\caption{Corner singularity in a domain.}
\label{fig:Elliptic:CornerSingularity}
\end{wrapfigure}

One could try to see what happens if we have corner singularities, for example, in a square domain. In a set inside of the square we will have perfect smoothness, but the corners may present problems.

Suppose we want to solve $- Δ u = 0$ in a corner such as \fref{fig:Elliptic:CornerSingularity}. In that case, we will work in polar coordinates and the basis of our solution will be \[φ_k(r,θ) = r^{\frac{kπ}{ω}} \sin \frac{kπθ}{ω} \]

The worst case would be $k = 1$, which would leave us in a case of $u ∈ H^s$ with $s < 1 + \sfrac{π}{ω}$. If $ω > π$ (the case of the square), we have $s < 2$, that is, we only have $H^1$ regularity.

We would have the same situation with Neumann conditions. However, mixed boundary conditions (Neumann on one side, Dirichlet on the other) are more problematic: the solutions are \[ φ_k(r,θ) = r^\frac{(k + \sfrac{1}{2})π}{ω} \sin \frac{(k + \sfrac{1}{2})πθ}{ω} \] and, in the worst case ($k = 0$) we have singularities even in the flat case ($ω = π$) which was not a problem in full Neumann or Dirichlet conditions.

\section{Advection-diffusion-reaction}

A more complex form of elliptic problems are advection-diffusion-reaction, where the differential operator is \[ Lu = - \sum_{i,j=1}^d \dpd{}{x_i} \left(a_{ij}\dpd{u}{x_j}\right) + \sum_{i=1}^d b_i \dpd{u}{x_i} + c u = - \dv (A(x) \grad u) + \vb(x) \grad u + c u\] with $A(x) ∈ ℝ^{d×d}, \vb(x) ∈ ℝ^d, c ∈ ℝ$. Our problem, as usual, is $Lu = f$.

These three terms model respectively diffusion, with $A$ being the matrix of coefficients that depend on the axis (the material is not uniform), the transport term along the vector field, and the reaction (for example, a chemical that reacts and its concentration decreases)

In order for the problem to remain elliptic, we require $A(x)$ to be positive definite for all $x ∈ ℝ^d$.

As in previous cases, we can have Dirichlet boundary conditions $\restr{u}{Γ_D} = g$ and Neumann boundary conditions (which are a little bit more complicated): \[ A \grad u · \vn - (b \vn) u = h \quad\text{ on } Γ_N \]

We will want to do a weak formulation where the boundary terms of the problem appear naturally. As always, we multiply by a test function and integrate by parts the divergence and possibly the $b \grad u$ depending on the boundary conditions. Without doing the computations, the weak formulation will end up being \( \int_Ω A \grad u \grad v + b \grad u v + c u v = \int_Ω fv + \int_{Γ_N} h v \label{eq:Elliptic:ADRProblemWeak} \) with $u ∈ H^1$, $\restr{u}{Γ_D} = g$.

This has the same structure as in previous cases, so we are in the conditions of the \nref{thm:Theory:LaxMilgram} and there exists a unique solution. Coercivity would need a little bit of work, and may present problems with mixed boundary conditions. Enforcing Neumann conditions on boundaries with incoming flow may cause problems with coercivity.

\section{Linear elasticity}

\begin{figure}[hbtp]
\inputtikz{ElasticDeformation}
\caption{Elastic deformation of a something.}
\label{fig:Elliptic:ElasticDeformation}
\end{figure}

In this problem, we start with an undeformed configuration $Ω ⊂ ℝ^d$, and we want to study the displacement $\appl{\vu}{Ω}{ℝ^d}$. The involved terms are the strain measure \[ ε (\vu) = \frac{\grad \vu + \trans{(\grad \vu)}}{2}\], the stress tensor $σ = σ(ε)$ given by \[ σ_{ij} = \sum_{k,l=1}^d c_{ijkl} ε_{kl} \], which usually can be expressed as \[ σ(ε) = 2με + λ\tr(ε) I \] with $μ,λ$ the Lamé constants.

With all of this, our balance equation is \( \begin{cases} - \dv σ(ε(\vu)) = \vec{f} & \text{in } Ω \\
\vu = \vec{g} & \text{on } Γ_D \\
σ(u) · \vn = \vd & \text{on } Γ_N \end{cases} \)

We may want to write now our weak formulation and integrate by parts, caring a little bit about what is a tensor and what is a vector
\begin{align*}
0
	&= \int_Ω \left[- \dv (σ(ε(\vu))) - \vec{f} \right] · \vv = \\
	&= \int_Ω σ(ε(\vu)) \grad \vv - \int_{∂Ω} (σ · \vn) · \vv - \int_Ω \vec{f} \vv \\
\int_Ω σ(ε(\vu)) \colon \vv &= \int_Ω \vec{f}\vv + \int_{Γ_N} \vd \vv
\end{align*}

I'm a little bit lost but \[ \int_Ω - \dv (σ) \vv = \int_Ω - \sum_i \sum_j ∂_j σ_{ij}v_i = \sum_{ij} \int_Ω σ_{ij}∂_jv_i - \int_{∂Ω}σ_{ij}n_j v_i \]

We can rewrite the first term because \begin{align*}
\int_Ω σ (ε(\vu)) \colon \vv
	&= \int_Ω σ(ε(\vu))\colon ε(\vv) = \\
	&= \int_Ω(2με(\vu) + λ\tr(ε(\vu))I) \colon ε(\vv) = \\
	&= \int_Ω 2με(\vu) \colon ε(\vv) + λ\tr(ε(\vu))I \colon ε(\vv) = \\
	&= \int_Ω 2μ \frac{\grad \vu + \trans{(\grad \vu)}}{2} \colon \frac{\grad \vv + \trans{(\grad \vv)}}{2} + λ\dv \vu \dv \vv = \\
	&= a(\vu, \vv)
\end{align*}

So we have a bilinear form again and whatever.

\section{Error estimates}

Along this section, we will see examples of elliptic problems and applying to them the error estimates devised in \fref{sec:Theory:ApproxResults}.

\subsection{Error estimates for finite element approximations}

Again, we discuss the estimates for the model problem and then we will see that the procedures generalize. This problem will be the Poisson equations with boundary conditions:
\[ \begin{cases}
-Δu =f & \text{in } Ω \\
∂_\vn u = d & \text{on } Γ_N \\
u= g & \text{on } Γ_D
\end{cases}\]

Its abstract weak form is the problem of finding a function $u ∈ V_g$ such that $a(u,v) = F(v)$ for any $v ∈ V_0$, with
\begin{align*}
V_g &= \set{v ∈ H^1(Ω) \tq \restr{v}{Γ_D} = g} \\
a(u,v) &= \int_Ω ∇u∇v \\
F(v) &= \int_Ω fv + \int_{Γ_N} d v
\end{align*} and assuming that $a$ is continuous ($a(u,v) ≤ M \norm{u}_V \norm{v}_V$) and coercive with coercivity coefficient $α = \frac{1}{1 + c_p^2}$, and $F$ a bounded linear operator. For the spaces $V_0, V_g$ we pick the $H^1$ norm.

Our finite element space will be $X_h^r$, the space of $P_r$ finite elements on the mesh $\mesh$. We can construct also the finite element space vanishing on the boundary as $V_{0,h} = X_h^r ∩ H_{Γ_D}^1$. The finite element space for $V_g$ is a little bit more tricky, but we can simply try to approximate the boundary value with the interpolation operator so $V_{h,g} = \set{ v_h ∈ X_h^r \tq \restr{v_h}{Γ_D} = I_h^r g}$.

If he have homogeneous Dirichlet boundary conditions (that is, $g \equiv 0$) we have the \nref{lem:Theory:Cea} which says that \[ \norm{u - u_h}_V ≤ \frac{M}{α} \inf_{v_h ∈ V_h} \norm{u - v_h}_V \]

With that, we can apply the error estimates for interpolation so that $\inf_{v_h ∈ V_{h,0}} \norm{u -v_h}_{H^1} ≤ \norm{u - I_h^r u}_{H^1} ≤ \abs{u}_{H^η}$ and our estimate is \[ \norm{u-u_h}_{H^1} ≤ C h^{η - 1} \abs{u}_{H^η} \] with $η = \min \set{r + 1, s}$ and $u ∈ H^s(Ω)$.

\subsubsection{Error estimate in $L^2$}

We will use the Aubin-Nitsche trick and we will use duality. In order to estimate the error, we define $e_h = u - u_h$ and the adjoint problem of searching for a $φ ∈ V$ such that \[ a(v,φ) = \int_{Ω} e_h v \qquad ∀v ∈ V\]

THis, in order to estimate the error in $L^2$ we can do the following: \[ \norm{u-u_h}^2_{L^2} = \norm{e_h}_{L^2}^2 = \int_Ω e_h e_h = a(e_h, φ) = a(u - u_h, φ) \]

By the Galerkin orthogonality condition, we know that $a(u - u_h, v_h) = 0$ for any $v_h ∈ V_h$. That allows to substract any $w_h ∈ V_h$ to φ, and then \[ a(u-u_h, φ) = a(u - u_h, φ - w_h) ≤ M \norm{u - u_h}_V \inf_{w_h ∈ V_h} \norm{φ-w_h}_V \]

We must know now which is the regularity of this function φ. To do that, we must notice that φ is the solution to the porblem \[
\begin{cases} - Δφ = e_h & \text{in } Ω \\
∂_\vn φ = 0 & \text{on } Γ_N \\
φ = 0 & \text{on } Γ_D
\end{cases} \] which in turn depends on the smoothness of $e_h$. We will use however only that $e_h ∈ L^2$, if Ω is a convex polygon. So, assuming $φ ∈ H^2$ we can bound the error in $L^2$, getting one more order of convergence: \[ \norm{u - u_h}_{L^2} ≤ C h \norm{u - u_h}_{H^1} \]

\chapter{Mixed problems}

\section{Introduction and examples}

Until now, we have studied problems with one differential operator of the form $L u = f$ with some boundary conditions. However, some PDE problems require more operators. One example that we will see with more detail later is the Darcy equation, which models the flow of a viscous fluid in a porous medium.

The main equation is given by conservation of mass: $\dv \vu = f$, where $\vu$ is the flow and $f$ a function giving sources and sinks in the system. However, we have also a constraint on the flow: it must be proportional to the gradient of a pressure function $p$, so $\vu = -k ∇ p$.

As we will see, these kinds of equations can be adapted to the following weak abstract formulation.

\begin{defn}[Weak\IS abstract formulation of a mixed PDE problem] The weak abstract formulation of a PDE problem is given by two Hilbert spaces $V,Q$ and two bilinear forms \begin{align*}
\appl{a}{V×V&}{ℝ} \\
\appl{b}{V×Q&}{ℝ}
\end{align*}

The problem is then finding $(u,p) ∈ V×Q$ such that \(
\begin{aligned}
a(u,v) + b(v,p) &= F(v) \quad ∀v ∈ V\\
b(u,q) &= G(q) \quad ∀q ∈ Q
\end{aligned} \label{eq:MixedProblemFormulation}
\)
\end{defn}

If we have the condition $G = 0$, we can define the space $V_0 = \set{v ∈ V \tq b(v,q) = 0 \; ∀q ∈ Q}$, which translates the problem to the usual abstract formulation of finding a $u ∈ V_0$ such that $a(u,v) = F(v)$ for any $v ∈ V_0$.

This type of construction will be useful when studying elliptic equations with constraints, such the incompressible elasticity equation. The problem will come on how to construct the approximation space to $V_0$. That is why sometimes we will nevertheless work on the unconstrained problem.

\begin{example}[Incompressible linear elasticity] In this case, we have a displacement field $\appl{\vu}{Ω}{ℝ^d}$. The strain tensor is the symmetric part of the gradient, so that \[ ε(\vu) = \frac{∇\vu + \trans{∇\vu}}{2} \] and the stress tensor will be just linear on the strain if we assume linear elasticity: \[ σ_{ij}(\vu) = C_{ijkl} ε_{kl} \]

For an isotropic equation, this tells us that the stress tensor is \[ σ(\vu) = 2με(\vu) + λ\tr(ε(\vu)) I\]

We have the following balance equations for the boundary conditions:
\begin{align*}
\dv σ(\vu) &= \vec{f} \quad\text{in }Ω \\
\vu &= \vec{g} \quad\text{on } Γ_D \\
σ(\vu) \vn &= \vd
\end{align*}

The weak formulation requires the definition of the space $V_g = \set{\vv ∈ (H^1)^d \tq \restr{\vv}{Γ_D} = \vec{g}}$, and thus the problem is finding a $\vu ∈ V_g$ such that \[ \int_Ω 2μ\left(ε(\vu) \colon ε(\vv)\right) + λ \dv \vu \dv \vv = \int_Ω \vec{f} \vv + \int_{Γ_N} \vd \vv \qquad ∀\vv ∈ V_0\]

The question is what happens if we have an incompressible material, that is, with $λ \to ∞$ (λ is the bulk modulus). What we do is formulate a variational problem: we define the energy of a solution as \[ J_λ(\vu) = \frac{1}{2} \int_{Ω} 2μ ε(\vu) \colon ε(\vu) + λ(\dv \vu)^2 - \int_Ω \vec{f} \vu - \int_{Γ_N} \vd \vu \]

Solving the minimization problem of $J_λ$ (that is, finding $\argmin_{\vu ∈ V_g} J_λ(\vu)$) is equivalent to the weak formulation presented above.

In that case, if $λ \to ∞$ the only way to bound the energy functional is to have $\dv \vu = 0$, so we will search then for the minimization function $\vu$ of the functional $J_0$ with $\vu ∈ V_g$ \textit{and} $\dv \vu = 0$, with \[ J_\text{inc}(\vu) = \frac{1}{2} \int_{Ω} 2μ ε(\vu) \colon ε(\vu) - \int_Ω \vec{f} \vu - \int_{Γ_N} \vd \vu  \]

To enforce the constraint, we can use Lagrange multipliers. The lagrangian will be then \[ \mathcal{L}(\vu,p) = J_0(\vu) - \int_Ω \vec{p} \dv \vu  \] with $\vec{p}$ being the Lagrange multiplier, and thus the problem is finding \[ \argmin_{\vu ∈ V_g} \max_{\vec{p} ∈ ?} \mathcal{L}(\vu, p) \] with the space of the Lagrange multiplier pending to define. To solve this, we write the ``derivatives'' and make them equal to 0 \begin{align*}
\dpd{\mathcal{L}}{\vu}(\vv) &= \lim_{ε \to 0} \frac{\mathcal{L}(\vu + ε \vv, p) - \mathcal{L}(\vu, p)}{ε} = \\ &= \int_Ω 2μ ε(\vu) \colon ε(\vv) - \int_Ω p \dv \vv - \int_Ω \vec{f} \vv - \int_{Γ_N} \vd \vv = 0 \\
\dpd{\mathcal{L}}{p}(q) &= \lim_{ε \to 0} \frac{\mathcal{L}(\vu, p  + ε q) - \mathcal{L}(\vu, p)}{ε} = \\ &= \int_Ω q \dv \vu = 0
\end{align*}

In the first case, the variation should be $0$ on the boundary so that $v ∈ V_0$, and in the second case we will need only $q ∈ L^2(Ω) = Q$ given that $\dv \vu$  is square-integrable.

So, finally, the constrained problem is finding $(u,p) ∈ V_g × Q$ such that \begin{align*}
\int_Ω 2μ ε(\vu) \colon ε(\vv) - \int_Ω p \dv \vv &= \int_Ω \vec{f} \vv + \int_{Γ_N} \vd \vv & ∀v ∈ V_0 \\
\int_Ω q \dv \vu &= 0 & ∀q ∈ Q
\end{align*}

THe trick is that we can adapt this to the mixed formulation of \eqref{eq:MixedProblemFormulation}, defining $a(\vu, \vv) = \int_Ω 2μ ε(\vu) \colon ε(\vv)$ and $b(\vv, p) = \int_Ω p \dv \vv$ (we only have to change the sign on the second equation but that does not change the equation).
\end{example}

\begin{example}[Nearly incompressible elasticity] Now on to the partial case: what happens if we have an object which is nearly incompressible? The issue is that if we have a very large value of λ (but not ∞) the error estimate constants blow up completely and we have a poor estimate. What we do in that case is to constrain $p = -λ \dv \vu$ and then the problem becomes \begin{align*}
\int_Ω 2μ ε(\vu) \colon ε(\vv) - \int_Ω p \dv \vv &= \int_Ω \vec{f} \vv + \int_{Γ_N} \vd \vv & ∀v ∈ V_0 \\
- \int_Ω q \dv \vu  -\underbracket{\frac{1}{λ} \int_{Ω} pq}_{c(p,q)} &= 0 & ∀q ∈ Q
\end{align*} which is the same problem as before but adding another term $c(p,q)$, which disappears when $λ \to ∞$, and so the solution will be robust when λ is very large.
\end{example}

\begin{example}[Flows in porous media] \label{exm:PDE:Darcy} To define the equations, we use Darcy's law: $\vu = -k ∇p$ with $p$ the pressure and $k$ the permeability. Also, fluid cannot disappear, so we have to force that, for any small domain ω, we have $\int_{∂ω} \vu \vn = \int_ω f$ where the left hand side is the fluid that gets in/out of the domain, and the right hand side is the sources or sinks in that domain. This gives us the following model:
\( \begin{aligned}
\dv \vu &= f \\
\vu &= -k∇p
\end{aligned} \label{eq:DarcyLaw} \)

We will also force that on the impervious boundaries $Γ_D$ we have no fluid transfer, that is, $\vu \vn = 0$ on $Γ_D$.

A first approximation would be to replace the velocity field and set $-\dv (k∇p) = f$ and the other boundary conditions, but that approach has issues. Mainly, that if we solve for $p$, the gradient will be a worse approximation and, specifically, if we have $f = 0$  (conservation of mass) then the approximate solution will not exactly conserve mass, which is definitely not very good. So, we need another approach deriving directly the weak formulation of \ref{eq:DarcyLaw}. For the divergence, we get directly by integration and multiplying by a test function $q$ so that \[ \int_Ω q \dv \vu = \int_Ω fq \]

In the other equation $\vu = -k∇p$, we use a test vector function $\appl{\vv}{Ω}{ℝ^d}$ and then integrate by parts:
\begin{align*}
\frac{1}{k} \vu &= - ∇p \\
\int_{Ω} \frac{1}{k} \vu \vv &= - \int_Ω ∇p \vv \\
\int_{Ω} \frac{1}{k} \vu \vv &= - \int_{Ω} p \dv \vv - \underbracket{\cancelto{0}{\int_{Γ_D} p \vv \vn}}_{\vv \vn = 0 \text{ on } Γ_D} - \int_{Γ_N} \vv \vn
\end{align*}

With this, we end with the mixed problem formulation given by
\(
\begin{aligned}
\underbracket{\int_{Ω} \frac{1}{k} \vu \vv }_{a(\vu, \vv)} + \underbracket{\left(- \int_Ω p \dv \vv \right)}_{b(\vv, p)} &= \underbracket{\int_{Γ_N} d \vv \vn}_{F(\vv)} \\
\underbracket{-\int_Ω q \dv \vu}_{b(\vu,q)} &= \underbracket{- \int_Ω fq}_{G(q)}
\end{aligned} \label{eq:DarcyLawWeakForm}
\)

As always, we need to know the spaces for $\vu, \vv$. We only need control on the divergence, so we can define \[ H(\dv, Ω) = \set{\appl{\vv}{Ω}{ℝ^d} \tq \vv ∈ (L^2(Ω))^d,\, \dv \vv ∈ L^2(Ω)} ⊃ (H^1(Ω))^d \] which is a smaller space than $(H^1(Ω))^d$ and with norm \( \norm{\vv}_{H(\dv, Ω)} = \norm{\vv}^2_{L^2(Ω)} + \norm{\dv \vu}^2_{L^2(Ω)} \label{eq:PDE:HDivNorm} \)

And, luckily for us, in this space we can define the trace operator as \begin{align*}
\appl{\tr}{H(\dv, Ω)&}{\left(H^{\sfrac{1}{2}}(∂Ω)\right)' = H^{-\sfrac{1}{2}}(∂Ω)} \\
\vv &\longmapsto \restr{\vv · \vn}{∂Ω}
\end{align*} with $H^{-\sfrac{1}{2}}(∂Ω)$ the dual space of $H^{\sfrac{1}{2}}(∂Ω)$. The trace operator is bounded \[ \norm{\vv · \vn}_{H^{-\sfrac{1}{2}}(∂Ω)} ≤ C \norm{\vv}_{H(\dv, Ω)} \]

This allows us to define the test function space $V_g = \set{\vv ∈ H(\dv, Ω) \tq \restr{\vv·\vn}{Γ_D} = g}$, and then we need to find $u ∈ V_g$ and $p ∈ L^2(Ω)$ to solve \eqref{eq:DarcyLawWeakForm}.
\end{example}

\section{Theoretical framework for the mixed problem}

So, after the examples, we will define the theorem that gives us the sufficient conditions for well-posedness of the mixed problem.

\begin{theorem}[Theorem\IS of existence and unicity for the mixed PDE problem] \label{thm:PDE:WellPosednessMixedProb} Let $V,Q$ be two Hilbert spaces and $V_0 = \set{v ∈ V \tq b(v,q) = 0 \; ∀q ∈ Q}$. Assume that:
\begin{itemize}
\item $\appl{a}{V×V}{ℝ}$ is a continuous (continuity bounding constant $M$) and coercive on $V_0$ ($∃ α > 0$ s.t. $a(u, u) ≥ α \norm{u}_V^2$ for any $v ∈ V_0$) bilinear form.
\item $\appl{b}{V×Q}{ℝ}$ is a continuous (continuity bounding constant $γ$) bilinear form and with an inf-sup condition: $∃β > 0$ such that \( \inf_{q∈Q}\sup_{v∈V} \frac{b(v,q)}{\norm{v}_V \norm{q}_Q} ≥ β > 0 \label{eq:PDE:InfSup} \) which is equivalent to saying that for any $q ∈ Q$ we have \[ \norm{q}_Q ≤ \frac{1}{β} \sup_{v ∈ V} \frac{b(v,q)}{\norm{\vv}_V} \]
\item $\appl{F}{V}{ℝ}$ and $\appl{G}{Q}{ℝ}$ are linear and bounded forms.
\end{itemize}

Under these conditions, there exists an unique solution $(u,p) ∈ V × Q$ for the problem \( \begin{aligned}
a(u,v) + b(v,p) &= F(v) \quad ∀v ∈ V\\
b(u,q) &= G(q) \quad ∀q ∈ Q
\end{aligned} \label{eq:PDE:MixedProblem}\) and there is a constant $C > 0$ such that \[ \norm{u}_V + \norm{p}_Q ≤ C\left(\norm{F}_{V'} + \norm{G}_{Q'}\right)\]
\end{theorem}

The inf-sup condition is actually very interesting, because it gives us the first introduction to the proof by forcing some properties on the following operator:
\( \begin{aligned}
\appl{\trans{B}}{Q&}{V'} \\
q &\longmapsto \pesc{\trans{B}q, ·} = b(·, q)
\end{aligned} \label{eq:PDE:MixedBTOperator} \)

The main property it forces is bijectivity with the image of its operator. This is important because for the proof we will try to get information on $u$ from $b(u,q) = G(q)$ and use that to solve $a(u,v) + b(v,p) = F(v)$, so it is important to have some kind of notion of the ``inverse'' of that operator $B$.

\begin{lemma} \label{lem:PDE:BijectivityOpBT} Let $\appl{\trans{B}}{Q}{V'}$ as defined on \eqref{eq:PDE:MixedBTOperator} and satisfying the inf-sup condition \eqref{eq:PDE:InfSup} . Then, $\trans{B}$ is bijective with its image, or equivalently:
\begin{enumerate}
	\item $\ker \trans{B} = \set{0}$ (or $\trans{B}$ is injective).
	\item $\img \trans{B}$ is closed.
\end{enumerate}
\end{lemma}

\begin{proof} Proofs are mostly straightforward for the two claims.

\proofpart{$\ker\trans{B} = \set{0}$}

As $b$ is continuous and fulfills the inf-sup condition, we can write \( β\norm{q} ≤ \norm{\trans{B}q}_{V'} ≤ γ \norm{q} \qquad ∀q ∈ Q  \) for two constants $β,γ > 0$. Now, let $q ∈ \ker \trans{B}$. In that case, $β\norm{q} ≤ \norm{\trans{B}q}_{V'} = 0$ so $\norm{q} = 0$ and $q = 0$.

\proofpart{$\img \trans{B}$ is closed.}

Take a Cauchy sequence in the image, then there is a corresponding Cauchy sequence of the preimages which has a limit because $Q$ is Banach. As $\trans{B}$ is continuous, the image of that limit is the limit of the Cauchy sequence in the image.
\end{proof}

However, $\trans{B}$ is not exactly the operator we want: we want its transpose. So let's define the operator \( \begin{aligned}
\appl{B}{V&}{Q'} \\
v &\longmapsto \pesc{Bv, ·} = b(v, ·) \end{aligned} \label{eq:PDE:MixedBOperator} \) which is continuous because $b$ is continuous.

What's the usefulness of starting by the transpose? Now we can apply the \nref{thm:Fund:ClosedRange}. We have that $\img \trans{B}$ is closed and as $\ker \trans{B} = \set{0}$, we have by the theorem $(\ker \trans{B})^\perp = Q' = \img B$ and $\left(\ker B\right)^\perp = \img \trans{B}$. This allows us to enunciate the following lemma:

\begin{lemma} \label{lem:PDE:BijectivityOpB} Let $\appl{B}{V}{Q'}$ as defined in \eqref{eq:PDE:MixedBOperator}. $B$ is surjective, $\restr{B}{\left(\ker B\right)^\perp}$ is bijective and there exists a constant $β > 0$ such that \[ \norm{Bu}_{Q'} ≥ β \norm{u}_V \qquad ∀u ∈ \left(\ker B\right)^\perp  \]

Moreover, there is a continuous inverse $\appl{\inv{B}}{Q'}{\left(\ker B\right)^\perp}$ with $\norm{\inv{B}} ≤ \sfrac{1}{β}$.
\end{lemma}

With this, we can prove the existence theorem.

\begin{proof}[\Fref{thm:PDE:WellPosednessMixedProb}]  As discussed previously, we will first try to invert $b(u,q) = G(q)$ to solve the first condition, and then we will retrieve $p$ from that solution.

\proofpart{Existence and uniqueness of $u$}

As $G ∈ Q'$, there exists its inverse via $B$ as defined in \eqref{eq:PDE:MixedBOperator}. Let $u_G = \inv{B} G ∈ V$. By \fref{lem:PDE:BijectivityOpB}, we know that $\norm{u_G} ≤ \frac{1}{β} \norm{G}$. Define $u_0 = u - u_G$. It is clear that $u_0 ∈ V^0$, a space we defined in the theorem as $V^0 = \set{v ∈ V \tq b(v,q) = 0 \; ∀q ∈ Q}$. We can then reformulate the first equation of \eqref{eq:PDE:MixedProblem} as \[ a(u_0, v) + b(v,p) = F(v) - a(u_G, v) \quad ∀v ∈ V \]

This is an elliptic coercive problem if we test for $v ∈ V^0$, so by \nref{thm:Theory:LaxMilgram} it has an unique solution with bound \[ \norm{u_0} ≤ \frac{1}{α} \sup_{v ∈ V^0} \frac{F(v) - a(u_G, v)}{\norm{v}} ≤ \frac{1}{α} \left(\norm{F} + M \norm{u_G} \right) \] and the solution $u$ is then bounded.

\proofpart{Recovery of $p$}

Now that we know $u$, we can recover $p$ which must fulfill \[ b(v,p) = F(v) - a(u,v) ≝ \tilde{F}(v) \quad ∀ v ∈ V \] or equivalently $\trans{B}p = \tilde{F}$.

If $v ∈ V^0$, then clearly $\tilde{F}(v) = 0$ so everything holds.\footnote{I mixed a little bit spaces and their orthogonal but everything is ok.}

\end{proof}

\subsection{General problem on Banach spaces}

So far, we have looked at equations $a(u,v) = F(v)$ with $u,v$ in Hilbert spaces. However, the inf-sup condition is much more well suited to define the well-posedness of the problem. Thus, we can work with $u,v$ in only Banach spaces.

We can write this in operator form. If we `freeze' $u ∈ V$ and let $v ∈ W$ vary, then $a(u,v) = \pesc{Au,v} $ with $\appl{A}{V}{W'}$. In the other direction, we have $\pesc{u, \trans{A}v} = a(u,v)$ with $\appl{\trans{A}}{W}{V'}$ the adjoint operator. In this expression, the inf-sup conditions imply the injectivity and surjectivity of the operator $A$ and its adjoint, and then the problem becomes finding an equality of functionals $A u = F ∈ W'$: if we have \[ \inf_{v∈W}\sup_{u∈V} \frac{a(u,v)}{\norm{u}_V \norm{v}_W} ≥ α > 0\] then we have $\ker \trans{A} = \set{0}$, $\img \trans{A}$ closed and $A$ surjective. If we additionally ask for the inverse inf-sup condition \[ \inf_{u∈V}\sup_{v ∈ W} \frac{a(u,v)}{\norm{u}_V \norm{v}_W} ≥ α > 0\] then we have unique solution $u$.

Even though these conditions are more general than the ones in the Lax-Milgram lemma, the problem is that they are far more difficult to prove than coercivity.

In the symmetric setting ($V = W$, $A = \trans{A}$) then only one check is necessary.

\begin{example} We can try to apply this to the Stokes elasticity problem. In the weak form, its equations were \( \label{eq:StokesElasticity} \begin{cases} \int ∇u ∇v - \int p \dv v = F(v) \\ \int q \dv u + ε \int pq = G(q) \end{cases} \)
, which can be simplified as a single bilinear form \[ A\left((u,p), (v,q)\right) = \int ∇u ∇v -\int p \dv v + \int q \dv u + ε \int pq \] and then check here the inf-sup condition, setting the norm of the tuple as $\norm{(u,p)}^2 = \norm{u}_V^2 + \norm{p}_Q^2$.

Given that $A$ is symmetric, we only have to prove that for any $(v,q)$ we have \[ \sup_{(u,p)} \frac{A\left((u,p), (v,q)\right) }{\norm{(u,p)}} ≥ α \norm{(v,q)} \], and for that it suffices to find a single $(u,p)$ for any $(v,q)$ for which $\frac{A\left((u,p), (v,q)\right) }{\norm{(u,p)}} ≥ α \norm{(v,q)}$.

Here, we would want to use $(u,p) = (v,q)$ which would give us however a little bit of bad control when $ε \to 0$, although then we can control it by something of the laplacian that was in the exercise and $q$ was like the gradient and something like that.
\end{example}

\section{Galerkin approximation}

Once we have the theoretical framework for the mixed problems, we will start working with the finite approximation and numerical solution model. Recall the general problem: find $(u,p) ∈ V×Q$ such that \begin{align*}
a(u,v) + b(v,p) &= F(v) \quad ∀v ∈ V \\
b(u,q) &= G(q) \quad ∀q ∈ Q
\end{align*}

To apply here the Galerkin approximation, we will define finite subspaces $V_h⊂V$ and $Q_h ⊂ Q$ with the approximation property that when $h \to 0$ they become ``dense'' in their respective parent spaces. More formally, we want for any $v ∈ V$ to have \[ \lim_{h \to 0} \inf_{v_h ∈ V_h} \norm{v - v_h} = 0\]  and the same for $Q$.

Once the spaces are defined, the Galerkin approximation problem will be to find $(u_h, v_h) ∈ V_h × Q_h$ such that \( \begin{aligned}
a(u_h,v_h) + b(v_h,p_h) &= F(v_h) \quad ∀v_h ∈ V_h \\
b(u_h,q_h) &= G(q_h) \quad ∀q_h ∈ Q_h
\end{aligned} \label{eq:GalerkinMixedProblem}\)

From here, we have to questions to answer: whether this approximated problem is well posed and how does it converge to the real solution when $h \to 0$.

\subsection{Well-posedness of the Galerkin approximation}

We will start, of course, by assuming that the original problem is well-posed and that $a,b$ fulfill the conditions of \fref{thm:PDE:WellPosednessMixedProb}. We will not have any problem with linearity and continuity as we are working on linear, closed subspaces. However, the coercivity of $a$ on $V_0$ and the inf-sup condition of $b$ may not necessarily hold.

We start by the inf-sup condition, which told us that \[ ∀q ∈ Q \quad \sup_{v ∈ V} \frac{b(v,q)}{\norm{v}_V} ≥ β \norm{q}_Q \]

It is easy to see that restricting $q$ to $Q_h$ maintains this relationship. However, if we restrict $v$ to $V_h$ we might lose that supremum and lose then the property. We will have to choose $V_h$ and $Q_h$ carefully so that restricting on $Q_h$ removes possible problems on that inequality. The discrete condition is the following \( ∀q_h ∈ Q_h \quad \sup_{v_h ∈ V_h} \frac{b(v_h, q_h)}{\norm{v_h}_{V_h}} ≥ β_h \norm{q_h}_{Q_h} \quad ∀ h > 0 \)

In particular, we will not be able to choose small spaces $V_h$ as in those we will have less ``options'' to find some $v$ that fulfills the condition.

What happens, however, if the condition is not satisfied? Then the operator $\trans{B}$ induced by $b$ is not injective, i.e. there exists a $q_h^*$ such that $b(v_h, q_h^*) = 0$ and $\ker \trans{B} ≠ \set{0}$. But then, if $(u_h, p_h)$ is a solution to \eqref{eq:GalerkinMixedProblem} then $(u_h, p_h + αq_h^*)$ is also a solution. This means we might have non-uniqueness or even non-existence if something happens with the second equation and the image of $G$ that completely passed over my head.

This problems tends to happen a lot in reality. Solutions like $q_h^*$ are called spurious solutions that are usually oscillatory. Thus, we will need to explicitly require the inf-sup condition at the discrete level.

The other problem was the coercivity on $V_0$ of $a$. However, if we have coercivity on the full space $V$, we will have coercivity too on any subspaces including $V_h$ and $V_{h,0} = \set{v_h ∈ V_h \tq b(v_h,q_h) = 0 \; ∀q_h ∈ Q_h}$ (the analogous space for the discrete setting).

For some PDE problems, such as the Stokes elasticity problem, coercivity on the full space $V$ will not be too much to ask and will come for free. However, in other problems such as the Darcy law, we only have control of the divergence on the restricted space and then we can't prove coercivity on the full space.

This prompts the question of what happens when $a$ is only coercive on $V_0$. We might be able to prove that $V_{h,0} ⊂ V_0$ so we have no problems, or maybe we are not able and then we have to prove specifically coercivity on the restricted discrete subspace. That depends heavily on the type of discretization used.

With all of this discussion, we can prepare the theorem for well-posedness\footnote{Frigging love existence and uniqueness theorems.}:

\begin{theorem} \label{thm:WellPosednessMixedGalerkin} Assume we start from a well-posed mixed PDE problem. Then, consider the Galerkin approximating problem of finding $(u_h, p_h) ∈ V_h × Q_h$ such that \[ \begin{aligned}
a(u_h,v_h) + b(v_h,p_h) &= F(v_h) \quad ∀v_h ∈ V_h \\
b(u_h,q_h) &= G(q_h) \quad ∀q_h ∈ Q_h
\end{aligned} \]

Assume that $a$ is coercive on $V_{h,0}$ \[ ∃ α_h > 0 \; a(v_h, v_h) ≥ α_h \norm{v_h}_V^2 \; ∀v_h ∈ V_{h,0} \] and $b$ satisfies the discrete inf-sup condition \[ ∃β_h > 0 \; \inf_{q_h ∈Q_h} \sup_{v_h ∈ V_h} \frac{b(v_h, q_h)}{\norm{v_h}_V \norm{q_h}_Q} ≥ β_h\]

Then, there exists an unique solution $(u_h, p_h) ∈ V_h × Q_h$ of the approximating problem and $\norm{u_h}_V + \norm{p_h}_Q ≤ C(\norm{F}_{V'} + \norm{G}_{Q'})$.
\end{theorem}

The inf-sup condition is considerably important as it gives us the uniqueness of the solution. If it does not hold, then there exists a $0 ≠ q_h^* ∈ Q_h$ such that $b(v_h, q_h^*) = 0\;∀v_h ∈ V_h$; so if $(u_h, p_h) ∈ V_h × Q_h$ is a solution then $(u_h, p_h + q_h^*) ∈ V_h × Q_h$ is another solution too.

\subsection{Convergence of the solution}

Next step, as always, is ensuring that we have good convergence conditions on the solution when we approximate well with finite element spaces.

\begin{theorem} \label{thm:WellPosednessMixedGalerkinConvergence} In the same conditions of \fref{thm:WellPosednessMixedGalerkin}, we can show that \[ \norm{u-u_h}_V + \norm{p - p_h} ≤ C\left(\inf_{v_h ∈ V_h} \norm{u - v_h}_V + \inf_{q_h ∈ Q_h} \norm{p - q_h}_Q \right) \] with $(u,p)$ a solution of the non-approximate problem.
\end{theorem}

\begin{proof} To prove this theorem, we will try to bound the $\norm{u_h - w_h}$ and $\norm{p_h - π_h}$ and then conclude by triangular inequality.

For the first one, let $w_h ∈ V_h$ such that $b(w_h, q_h) = G(q_h)$ for any $q_h ∈ Q_h$. In that case, we have $u_h - w_h ∈ V_{h,0}$ and there we have coercivity, so we can write \[ \norm{u_h - w_h}^2 ≤ \frac{1}{α_h}a(u_h - w_h, u_h - w_h)\]

Adding and substracting $u$ in the arguments of $a$; we have that
\begin{multline*} \frac{1}{α_h}a(u_h - w_h, u_h - w_h) = \frac{1}{α_h}\left(a(u_h - u, u_h - w_h) + a(u -w_h, u - w_h)\right) = \\ = \frac{1}{α_h} \left(F(u_h, w_h) - b(u_h - w_h, p_h) - F(u_h - w_h) + b(u_h - w_h, p) + a(u - w_h, u_h - w_h)\right)\end{multline*}

However, given that $u_h - w_h ∈ V_{h,0}$, we have $b(u_h - w_h, p_h) = 0 = b(u_h - w_h, π_h)$ so the equation becomes \begin{align*}
\norm{u_h - w_h}^2 &= \frac{1}{α_h} \left(F(u_h, w_h) - b(u_h - w_h, p_h) - F(u_h - w_h) + b(u_h - w_h, p) + a(u - w_h, u_h - w_h)\right) \\
	&= \frac{1}{α_h}\left(b(u_h - w_h, p - π_h) + a(u-w_h, u_h - w_h)\right) \\
	&≤ \frac{1}{α_h}\left(γ \norm{p - π_h}_Q \norm{u_h - w_h}_V + M \norm{u -w_h}\norm{u_h - w_h}\right) \\
\norm{u - u_h}_V &≤ \frac{γ}{α_h} \norm{p - π_h}_Q + \frac{M}{α_h}\norm{u -w_h}
\end{align*}

With this, we can bound $\norm{u - u_h}$ as $w_h, π_h$ are arbitrary so that \begin{align*}
\norm{u -u_h}_V &≤ \norm{u - w_h} + \norm{u_h - w_h} \\
&≤ \left(1 + \frac{M}{α_h}\right) \norm{u - w_h} + \frac{γ}{α_h} \norm{p - π_h} \\
\norm{u - u_v}_V &≤ \left(1 + \frac{M}{α_h}\right)\inf_{w_h ∈ V_h} \norm{u - w_h} + \frac{γ}{α_h} \inf_{π_h ∈ Q_h} \norm{p - π_h}
\end{align*} so we are done.

Now we need to recover the bound on $p$ so we have \begin{align*}
\norm{p - π_h} &≤ \frac{1}{β_h} \sup_{v_h ∈ V_h} \frac{b(v_h, p_h - π_h)}{\norm{v_h}} \\
&≤ \frac{1}{β_h} \sup\frac{b(v_h, p_h - p)}{\norm{v_h}} + \frac{1}{β_h} \underbracket{\sup \frac{b(v_h, p - π_h)}{\norm{v_h}}}_{≤ γ\norm{p - π_h}} \\
&≤ \frac{1}{β_h} \sup \frac{a(u - u_h,v_h)}{\norm{v_h}} + \frac{γ}{β} \norm{p - π_h} \\
&≤ \frac{M}{β_h} \norm{u - u_h} + \frac{γ}{β_h} \norm{p - π_h}
\end{align*} and then we have the triangular inequality \[ \norm{p - p_h} ≤ \norm{p - π_h} + \norm{p_h - π_h} ≤ \dotsb ≤ C\left(\inf_{w_h} \norm{u - w_h} + \inf_{π_h ∈ Q_h} \norm{p-π_h} \right)\]

We need to take care however that $w_h$ fulfills that $b(w_h, q_h) = G(q_h)$, which is a little bit annoying because we can't take the interpolant to bound $\inf_{w_h} \norm{u - w_h}$. So, let $V_h^G = \set{w_h ∈ V_h \tq b(w_h, q_h) = G(q_h) \; ∀q_h ∈ Q_h}$, and the missing step is to prove that if $b$ satisfies the discrete inf-sup condition then $\inf_{w_h ∈ V_h^G} \norm{u - w_h} ≤ C \inf_{v_h ∈ V_h} \norm{u - v_h}$.
\end{proof}

\section{Application: Linear elasticity problem}

We are going to apply now the previous theory to the linear elasticity theory. We will have our domain $Ω ⊂ ℝ^d$, and our two Hilbert spaces $V = \left[H_{Γ_D}^1(Ω)\right]^d$ ($d$-dimensional $H^1$ functions on $Ω^d$ that are $0$ on the Dirichlet boundary $Γ_D ⊂ ∂Ω$) and $Q = L^2(Ω)$. The bilinear forms are \begin{align*}
a(u,v) &= 2 \int_Ω με(\vu) \colon ε(\vv) \dif x \\
b(v,p) &= \int_Ω p \dv \vv \dif x \\
F(v) &= \int_Ω fv \dif x + \int_{Γ_N} \vd · \vn \dif x \\
G(q) &= 0
\end{align*} where \[ ε(u) = \frac{∇\vu + \trans{∇\vu}}{2} \qquad A \colon B = \tr(A \trans{B}) \]

The untrusting reader should check that $a$ is continuous and coercive, $b$ is continuous and $F$ is bounded. These are not difficult and can be seen directly. However, the proof of the inf-sup condition is a little bit more ``interesting''. To make our lifes easier, we will assume that we don't have any boundary conditions, and that our domain is convex and with Lipschitz boundary.

Now, for any $p ∈ L^2(Ω)$, let $\appl{ψ}{Ω}{ℝ}$ of the following PDE: \( \begin{cases} Δψ = p & \text{ in } Ω \\ ψ = 0 & \text{ on } ∂Ω \end{cases} \label{eq:Mixed:AuxPDEPressure} \)

We know that \eqref{eq:Mixed:AuxPDEPressure} has an unique solution of regularity $H^2$ by the \nref{thm:PDE:Shift} and bounded with $\norm{ψ}_{H^2(Ω)} ≤ C^* \norm{p}_{L^2(Ω)}$. Set now $\vv ≝ ∇ψ ∈ V$, so that $\dv \vv = p$ with bound $\norm{\vv}_V ≤ C^* \norm{p}_Q$.

With this, we can start prove the inf-sup condition: \[ \frac{b(\vv,p)}{\norm{\vv}_V} = \frac{\int_Ω \dv \vv p \dif x }{\norm{\vv}_V} = \frac{\norm{p}^2_Q}{\norm{v}_Q} ≥ \frac{1}{C^*} \norm{p}_Q\]

\subsection{Numerical approximation}

Once we know that the continuous problem has an unique solution, we look at the Galerkin approximation problem of finding $(u_h, p_h) ∈ V_h × Q_h$, with $V_h, Q_h$ finite approximation spaces, such that \[ \begin{aligned} a(u_h, v_h) + b(v_h, p_h) &= F(v_h) & ∀ v_h ∈ V_h \\ b(u_h, q_h) &= 0 & ∀q_h ∈ Q_h \end{aligned} \]

We will need to define the space of functions that fulfill the second equation: \[ V_h^0 = \set{v_h ∈ V_h \tq b(v_h, q_h) = 0 \; ∀q_h ∈ Q_h} \]

For the finite element spaces, we can choose piecewise continuous polynomials of degree $r$ (space $X_h^r$) to approximate $V$, and piecewise non-necessarily continuous polynomials of degree $r$ (space $Y_h^r$) to approximate $Q$ (it's just $L^2$ so we don't need regularity).

However, choosing the domains is not trivial. $X_h^0, Y_h^1$ do not satisfy the inf-sup condition, and in general $X_h^r, Y_h^r$ do not satisfy it because of the same degree.

One polynomial space that will be useful for constructing approximation spaces with the inf-sup condition will be bubble spaces.

\begin{defn}[Bubble space][Space!bubble] Given a triangular mesh element $K ⊂ ℝ^d$, we can define a bubble space by defining $φ_K ∈ \pspace[d + 1](K)$ such that $\restr{φ_K}{∂K} = 0$. Then, adding this element to the base of $\pspace[1](K)$ gives $\pspace[1]^b(K)$, the bubble space.

This space allows the recovery of the inf-sup condition but does not improve accuracy, which is only first order accurate.
\end{defn}

In general, however, the combination of spaces $\pspace/\pspace[r -1]$ gives the inf-sup condition and a $r$\textsuperscript{th} order approximation.

\chapter{Darcy problem - Approximation of vector valued functions}

Along this chapter we will study the Darcy problem, which models the flow of a fluid in a saturated porous medium. Its equation are the following:
\( \label{eq:PDE:Darcy} \begin{cases}
\frac{1}{k} \vu + ∇p = 0 & \text{in } Ω \\
\dv \vu = f & \text{in } Ω \\
p = d & \text{on } ∂Ω
\end{cases}\) with $f ∈ L^2(Ω)$, $d ∈ H^{\sfrac{1}{2}}(∂Ω)$ and $0 < k_{\text{min}} ≤ k(x) ≤ k_{\text{max}} < ∞$ for all $x ∈ Ω$. For easiness of presentation we will use only Neumann boundary conditions, although it generalizes without difficulty with Dirichlet conditions.

In the \fref{exm:PDE:Darcy} we already derived an abstract weak formulation of the problem, which is that of finding $\vu ∈ H(\dv, Ω) ≝ V$ and $p ∈ L^2(Ω) ≝ Q$ such that \( \begin{cases}a(\vu, \vv) + b(\vv, p) = F(\vv) & ∀v ∈ V \\
b(\vu, q) = G(q) & ∀q ∈ Q
\end{cases} \label{eq:PDE:DarcyWeakAbs} \) with \begin{align*}
a(\vu, \vv) &= \int_Ω \frac{1}{k} \vu \vv & F(\vv) &= \int_{∂Ω} d · \vv · \vn_{∂Ω} \\
b(\vv, p) &= - \int_{Ω} p \dv \vv & G(q) &= - \int_{Ω} fq
\end{align*}

We need to check assumptions of \nref{thm:PDE:WellPosednessMixedProb} to ensure well-posedness of \eqref{eq:PDE:DarcyWeakAbs}. Continuity of $a, b, G$ is straightforward. For $F$, it comes from the \nref{thm:Fund:Trace}: \[ F(\vv) = \int_{∂Ω} d \vv · \vn_{∂Ω} ≤ \norm{d}_{H^{\sfrac{1}{2}}(∂Ω)} \norm{\vv · \vn_{∂Ω}}_{H^{-\sfrac{1}{2}} (∂Ω)} ≤ γ \norm{d}_{H^{\sfrac{1}{2}}(∂Ω)} \norm{\vv}_{H(\dv, Ω)} \]

For the coercivity of $a$ in $V_0 = \ker B = \set{\vv ∈ H(\dv, Ω) \tq \dv \vv = 0}$, we have it immediately because of the definition\footnote{As defined in \eqref{eq:PDE:HDivNorm}, we have $\norm{\vu}_{H(\dv, Ω)}^2 = \norm{\vu}_{L^2(Ω)}^2 + \norm{\dv \vu}_{L^2(Ω)}^2$.}
of the norm in $H(\dv, Ω)$:
\[
	a(\vu, \vu) = \int_{Ω} \frac{1}{k} \abs{\vu}^2 ≥ \frac{1}{k_{\text{max}}} \norm{\vu}^2_{L^2(Ω)} = \frac{1}{k_{\text{max}}} \norm{\vu}^2_{H(\dv,Ω)}
\]

However, $a$ would not be coercive on the full space $V$.

For the inf-sup condition on $b$, for any $p ∈ L^2(Ω)$ we can define $ψ ∈ H^1(Ω)$ as the solution to the Dirichlet problem $Δψ = p$ in $Ω$ with $\restr{ψ}{∂Ω} = 0$, and let $\vv_p = ∇ψ$. Clearly $v_p ∈ H(\dv, Ω)$ and it's bounded by $\norm{\vv_p}_{H(\dv, Ω)} ≤ C\norm{p}_{L^2(Ω)}$ so that \[ \sup_{\vv ∈ V} \frac{b(\vv, p)}{\norm{\vv}} ≥ \frac{b(\vv_p, p)}{\norm{\vv_p}} = \frac{\norm{p}^2}{\norm{\vv_p}} ≥ \frac{1}{C} \norm{p} \]

Therefore all the assumptions of the \nref{thm:PDE:WellPosednessMixedProb} are fulfilled and the problem is well-posed. However, we do not know exactly how to approximate velocity fields $\vu ∈ H(\dv, Ω)$ with finite elements, so we will go and see that.

\section{Raviart-Thomas finite element spaces}

We also need a basis of functions for a vector valued functions. This will be the Raviart-Thomas spaces, that we will construct on a triangular mesh \mesh.

\begin{defn}[Raviart-Thomas finite element space][Finite elements space!Raviart-Thomas] Given an element $κ ∈ ℝ^d$ of a triangular mesh, the Raviart-Thomas $\mop{RT}_r$ space of degree $r$ is given by functions of the form $\vv(\vx) = \vec{w} + \vx η$ where $\vec{w} ∈ \left(\mathbb{P}_r(κ)\right)^d$ and $η ∈ \mathbb{P}_r(κ)$.
\end{defn}

This space has several nice properties.

\begin{prop} Let $\mop{RT}_r(κ)$ be the Raviart-Thomas finite element space. Then the following properties hold:
\begin{enumerate}
	\item $\left(\mathbb{P}_r(κ)\right)^d ⊂ \mop{RT}_r(κ) ⊂ \left(\mathbb{P}_{r+1}(κ)\right)^d$.
	\item If $\vv ∈ \mop{RT}_r(κ)$ and $e ⊂ ∂κ$ is an edge of the mesh, then $\vv · \vn ∈ \mathbb{P}_r(e)$.
\end{enumerate}
\end{prop}

These basis functions allows us to define the $\mop{RT}_r$ global space as \( \label{eq:Mixed:RTSpace} W_h^r = \set{\appl{\vv}{Ω}{ℝ^d} \tq \restr{\vv}{κ} ∈ \mop{RT}_r(κ), \, \restr{\vv · \vn}{e} = 0 \, ∀e ⊂ E(∂κ)\, ∀κ ∈ \mesh} \) where $E(∂κ)$ is the set of edges of the element κ.

To prove that this space is useful, we will need the definition of the distributional divergence, done in the usual fashion: $\pesc{\dv \vv, φ} = - \pesc{\vv, \dv φ}$.

\begin{lemma} $W_h^r ⊂ H(\dv, Ω)$
\end{lemma}

\begin{proof} Clearly, if $\vv ∈ W_h^r$ then $\vv ∈ \left(L^2(Ω)\right)^d$. The question is if the distributional derivative is in $L^2(Ω)$ too.
\end{proof}

\begin{lemma}[Interpolation error\IS for Raviart-Thomas finite elements] Given a family of regular triangulations $\set{\mesh}_{h > 0}$ of a polygonal domain $Ω ⊂ ℝ^d$ with $d ≤ 3$ and the space $W_h^r$ of Raviart-Thomas finite elements of degree $r ≥ 0$, it holds \( \label{eq:PDE:RTApprox} \norm{\vv - I_{h}^{\mop{RT}_r} \vv}_{H(\dv, Ω)} ≤ C^{r+1} \left(\abs{\vv}_{H^{r+1}(Ω)} + \abs{\dv \vv}_{H^{r+1}(Ω)}\right) \qquad ∀\vv ∈ \left[H^{r+1}(Ω)\right]^d\) with a constant $C > 0$ independent of $h$.
\end{lemma}
